{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "singleFCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHgvyNWX1XmN4yNWtmDAA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokiAndere/ML-tutties/blob/main/singleFCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4kFgqxh2kem",
        "outputId": "43844ecf-066b-4015-c598-e7db70b2f5f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cz38Km5vW8"
      },
      "source": [
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCe-ofUcd8lt"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import zscore\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYwq6vEXzaqP"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo7H0HEHzbE2"
      },
      "source": [
        "import keras.backend as BCKN\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "from keras.layers import Dropout, Flatten, Dense, DepthwiseConv2D, GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization as BN\n",
        "from keras.layers import ReLU, Softmax\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veEVrIWQzisk"
      },
      "source": [
        "def FCNN (shape, num_classes):\n",
        "  def CR (model, filters):\n",
        "    model = Conv2D(filters, 3) (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  def CRCRMP (model, filters):\n",
        "    model = CR(model, filters)\n",
        "    model = CR(model, filters)\n",
        "    model = Conv2D(filters, 2, strides = 2) (model)\n",
        "    return model\n",
        "\n",
        "  def DR (model, filters):\n",
        "    model = Dense(filters) (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  first = Input (shape)\n",
        "  model = CRCRMP (first, 16)\n",
        "  model = CRCRMP (model, 64)\n",
        "  model = Dropout (0.2) (model)\n",
        "  model = CR (model, 64)\n",
        "  model = CR (model, 128)\n",
        "  model = BN () (model)\n",
        "  model = Flatten () (model)\n",
        "  model = DR (model, 64)\n",
        "  model = Dropout (0.2) (model)\n",
        "  model = DR (model, 32)\n",
        "  model = DR (model, 32)\n",
        "  model = Dense (num_classes) (model)\n",
        "  last = Softmax () (model)\n",
        "  final = Model (first, last)\n",
        "  return final"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIYak3hOzvAV"
      },
      "source": [
        "shape = (100, 100, 1)\n",
        "num_classes = 2"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JwobILMzyTI",
        "outputId": "f5a2ed67-5846-4e92-dced-1e70b3642a2c"
      },
      "source": [
        "BCKN.clear_session()\n",
        "model = FCNN(shape, num_classes)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 98, 98, 16)        160       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 98, 98, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 16)        2320      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 96, 96, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 16)        1040      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 46, 46, 64)        9280      \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 44, 44, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 22, 22, 64)        16448     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 128)       73856     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                2654272   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,834,946\n",
            "Trainable params: 2,834,690\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOZJ3Uhc0J4q"
      },
      "source": [
        "def MobNet (shape, num_classes, alpha=1, ro=1, filter_one=32):\n",
        "\n",
        "  #alpha should be 1/4, 1/2, 3/4, 1\n",
        "  #basically between 0 and 1\n",
        "  #it is a reduce multiplyer of net arcitecture\n",
        "  #ro is reduce multiplyer of input image\n",
        "  #also between 0 and 1\n",
        "\n",
        "  #also additionally we included the number of filters to begin with\n",
        "  #instead of 32 we can put another minimum 16 and then we grow it like 2**n\n",
        "\n",
        "  #remember to reshape the image accordingly\n",
        "\n",
        "  #block that puts batch normalization and relu\n",
        "  #because we are tired of writing it each time\n",
        "  def BNR(model):\n",
        "    model = BN() (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  #standart block\n",
        "  #you guessed it each convolution is proceeded with\n",
        "  #batch normalization and linear rectifier relu\n",
        "  def CBNR(model, filters, kernal, stride=1, padd='same'):\n",
        "    model = Conv2D (filters, kernal, strides=stride, padding=padd) (model)\n",
        "    model = BNR(model)\n",
        "    return model\n",
        "\n",
        "  #combo block\n",
        "  #deepwise convolution, in this way we save computational potency\n",
        "  #instead of one big convolutional block we brake it into two\n",
        "  #the first one is deepwise second is simple convolution\n",
        "  #less coeficients appear in this way\n",
        "  #too bad we did not perserve time to play with permute in all these exercises\n",
        "  #first convolution as easch convolution in this method\n",
        "  #is proceeded with batch normalization and relu\n",
        "  #and standart block inside\n",
        "  #we mean look at the name\n",
        "  #it is very self explainatory DCBNRCBNR\n",
        "  #for those to whom it is hard to read this\n",
        "  #we put a down underline separator\n",
        "  def DCBNR_CBNR(model, filters, stride=1, padd='same'):\n",
        "    model = DepthwiseConv2D(3, strides=stride, padding=padd) (model)\n",
        "    model = BNR(model)\n",
        "    model = CBNR(model, filters, 1)\n",
        "    return model\n",
        "\n",
        "  #we fill the arcitecture of light net\n",
        "  def fill(alpha=1, filters=32):\n",
        "    new_list = []\n",
        "    if filters<16:\n",
        "      filters = 32\n",
        "    if alpha<=0 or 1<alpha:\n",
        "        alpha=0.5\n",
        "    for n in range(6):\n",
        "        new_list.append(int(filters*alpha*2** n))\n",
        "    return new_list\n",
        "\n",
        "  if ro<=0 or 1<ro:\n",
        "    ro=0.5\n",
        "  tmp=list(int(s*ro) for s in shape[:-1])\n",
        "  tmp.append(shape[-1])\n",
        "  shape=tuple(tmp)\n",
        "\n",
        "  first = Input(shape)\n",
        "  #arch stends for arcitecture\n",
        "  arch = fill(alpha, filter_one)\n",
        "  #it seems like we can imagine a better automatization\n",
        "  #like one complex cycle\n",
        "  #because number of filters frows in a simple row a(n)=2^n\n",
        "  #but at this point we have not figured out it\n",
        "  #and from another point of view it is more readable\n",
        "  #and corelates strongly to paper table\n",
        "  model = CBNR(first, arch[0], 7, 2)\n",
        "  model = DCBNR_CBNR(model, arch[1])\n",
        "  model = DCBNR_CBNR(model, arch[2], 2)\n",
        "  model = DCBNR_CBNR(model, arch[2])\n",
        "  model = DCBNR_CBNR(model, arch[3], 2)\n",
        "  model = DCBNR_CBNR(model, arch[3])\n",
        "  model = DCBNR_CBNR(model, arch[4], 2)\n",
        "  for _ in range (5):\n",
        "    model = DCBNR_CBNR(model, arch[4])\n",
        "  model = DCBNR_CBNR(model, arch[5], 2)\n",
        "  #this one is strange. in the paper it is said to have stride step 2\n",
        "  #but the dimentions say it has to have stride = 1\n",
        "  model = DCBNR_CBNR(model, arch[5])\n",
        "\n",
        "  #tail\n",
        "  model = GlobalAveragePooling2D() (model)\n",
        "  model = Dense(num_classes) (model)\n",
        "  last = Softmax() (model)\n",
        "  final = Model(first, last)\n",
        "\n",
        "  return final"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt2J_TD10XjG",
        "outputId": "f62ab685-e18a-446d-c644-fb1f3a2eb0fc"
      },
      "source": [
        "shape = (100, 100, 1)\n",
        "num_classes = 2\n",
        "alpha=0.25\n",
        "romashka=1\n",
        "first=16\n",
        "BCKN.clear_session()\n",
        "modelS = MobNet(shape, num_classes, alpha, romashka, first)\n",
        "modelS.summary()\n",
        "#plot_model(modelS, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 50, 50, 4)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 50, 50, 4)         16        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 50, 50, 4)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseC (None, 50, 50, 4)         40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 50, 50, 4)         16        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 50, 50, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 50, 50, 8)         40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 50, 50, 8)         32        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 50, 50, 8)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_1 (Depthwis (None, 25, 25, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 25, 25, 8)         32        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 25, 25, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 25, 25, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_2 (Depthwis (None, 25, 25, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 25, 25, 16)        272       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_3 (Depthwis (None, 13, 13, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 32)        544       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_4 (Depthwis (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 32)        1056      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_10 (ReLU)              (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_5 (Depthwis (None, 7, 7, 32)          320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "re_lu_11 (ReLU)              (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 64)          2112      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_12 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_6 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_13 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_14 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_7 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_15 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_16 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_8 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_17 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_18 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_9 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_19 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_20 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_10 (Depthwi (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_21 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_22 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_11 (Depthwi (None, 4, 4, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_23 (ReLU)              (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 128)         8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_24 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_12 (Depthwi (None, 4, 4, 128)         1280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_25 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 128)         16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_26 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 61,930\n",
            "Trainable params: 59,194\n",
            "Non-trainable params: 2,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMQ5Hb9_Vfz"
      },
      "source": [
        "def normalize_zero_simple(x):\n",
        "  return (x.astype(float) - 128)/128\n",
        "\n",
        "def normalize_channel_vise(x):\n",
        "  x = x.astype('float32')\n",
        "  return (x - x.mean(axis = (0, 1, 2), keepdims = True)) / x.std(axis = (0, 1, 2), keepdims = True)\n",
        "\n",
        "def normalize_channel_vise_02(x):\n",
        "  x = x.astype('float32')\n",
        "  return zscore(x.reshape(-1, 3)).reshape(x.shape)\n",
        "\n",
        "def normalize_manually(x):\n",
        "  x = x.astype('float32')\n",
        "  x /= 255.0\n",
        "  return x\n",
        "\n",
        "def global_centering(x):\n",
        "  x = x.astype('float32') \n",
        "  x = x - x.mean()\n",
        "  return x\n",
        "\n",
        "def local_centering(x):\n",
        "  x = x.astype('float32')\n",
        "  means = x.mean(axis=(0,1), dtype='float64')\n",
        "  x =  x - means\n",
        "  return x\n",
        "\n",
        "def global_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  mean, std = x.mean(), x.std()\n",
        "  x = (x - mean) / std\n",
        "  return x\n",
        "\n",
        "def positive_global_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  mean, std = x.mean(), x.std()\n",
        "  x = (x - mean) / std\n",
        "  x = np.clip(x, -1.0, 1.0)\n",
        "  x = 0.5 * (x + 1.0)\n",
        "  return x\n",
        "\n",
        "def local_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  means = x.mean(axis=(0,1), dtype='float64')\n",
        "  stds = x.std(axis=(0,1), dtype='float64')\n",
        "  x = (x - means) / stds\n",
        "  return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io7O1ZyP1xja"
      },
      "source": [
        "def draw_mpl(im, name = 'origin'):\n",
        "  name = name.title()\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.canvas.set_window_title(name.upper())\n",
        "  ax.set_title(label=name, fontsize=16, color=\"black\")\n",
        "  ax.set_xlabel('x')\n",
        "  ax.set_ylabel('y')\n",
        "  ax.xaxis.set_ticks_position('top')\n",
        "  ax.xaxis.set_label_position:('top')\n",
        "  ax.xaxis.set_title_position:('top')\n",
        "  plt.imshow(im, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVBJGequ0keA"
      },
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/DefectDetection/100x100/'\n",
        "ARR_PATH = '/content/drive/MyDrive/DefectDetection/tog.npz'\n",
        "NARR_PATH = '/content/drive/MyDrive/DefectDetection/togn.npz'\n",
        "data = np.load(ARR_PATH)\n",
        "ndata = np.load(NARR_PATH)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av3Sz2da0uPQ",
        "outputId": "edb6327b-880b-4e1b-ec3f-7487e2308db6"
      },
      "source": [
        "X, y = data['x'], data['y']\n",
        "#X, y = ndata['xn'], ndata['yn']\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(347, 100, 100) (347,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrKukxPC_75q"
      },
      "source": [
        "#X = preprocess_input(X)\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#scaler = Normalizer()\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8pijOC68o98"
      },
      "source": [
        "for i in range (X.shape[0]):\n",
        "  #X[i] = global_standardization(X[i])\n",
        "  #X[i] = positive_global_standardization(X[i])\n",
        "  X[i] = local_standardization(X[i])\n",
        "  #X[i] = preprocessing.normalize(X[i]) #ok for 2 dimentions\n",
        "  #X[i] = scaler.fit_transform(X[i])\n",
        "  #X[i] = normalize_channel_vise_02(X[i])\n",
        "  pass"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6XtIHq_571j",
        "outputId": "14358a17-3e2a-4550-c57b-edf64d105dc6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, stratify=y_train) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "print(Counter(y_train))\n",
        "print(Counter(y_test))\n",
        "print(Counter(y_val))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(207,)\n",
            "(70,)\n",
            "(70,)\n",
            "Counter({0: 129, 1: 78})\n",
            "Counter({0: 44, 1: 26})\n",
            "Counter({0: 43, 1: 27})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6BhoR2HTLhQ"
      },
      "source": [
        "X_train = X_train.reshape(207,100,100,1)\n",
        "X_test = X_test.reshape(70,100,100,1)\n",
        "X_val = X_test.reshape(70,100,100,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test =X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "#X_train /= 255.0\n",
        "#X_test /= 255.0\n",
        "#X_val /= 255.0\n",
        "y_train=to_categorical(y_train, num_classes)\n",
        "y_test=to_categorical(y_test, num_classes)\n",
        "y_val=to_categorical(y_val, num_classes)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "j4zZiH7v15sm",
        "outputId": "a3a9f102-d320-4e70-b61c-e26451247fe0"
      },
      "source": [
        "i = 11\n",
        "draw_mpl(X[i], f\"sample {i}, label {y[i]}\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEYCAYAAABP4gNaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebQs3VUf9jvdNXT1PN15eu+TPhkesECExAIl9hcghgBhCovIgBBYQSsTg00MksC2ktgYshKwvOxFLAMWBtmCAAEig2QMCKI4CCwQ/kDSp+G9d+/tO/Vwe+6urq6qkz+693lVdavH2327+77+rXXXe91dXXX61Kl99tnnt3+bcc6xxhprrDEIgUU3YI011lhurI3EGmusMRRrI7HGGmsMxdpIrLHGGkOxNhJrrLHGUKyNxBprrDEUayMxJhhjX88Y+33GWJ4x1maMHTPGfpUx9pWLbtsgMMbezRh7OsPz/Q3G2P/NGLtgjHHG2DsGHPdfMMb+BWPsk4wxmzH2wVte96X+9b78Nufpn+vdjLHcbc/jON87GGNj8Qj6Y+hPGGN6f/z8MGMsOKu2zAtrIzEGGGPfA+D/AvApAG8G8NUA/m7/4y9dVLsWgO8CsAngV0cc9/UAvgDAHwCY2QO5ymCMfQWAXwbwRwD+cwDvBPDDAH5kke0aB9KiG7Ai+B8B/Crn/M2O934HwD9ljD1PhvZzOOc2Y0wC8N8MOe67OOc2ADDGPnQ3TVt6/CiAD3HO39J//buMsSiAH2aM/QTn/HKBbRuK52mA3wZpAL43kR4GAGCMbTDG/knfzW4xxk77bvee8zvkojLGPosx9gHGWJMxdsIY+87+529kjH2CMdZgjP0uY+xVnu8/ZYz9PGPsuxhjn+67r3/MGPtPR/0QxliYMfZjjLEnjDGj/+8PjWPsnL91FsfNEoyxVzPGfq7/e9qMsceMsZ9kjKUGHP8ljLE/6vfdU8bYd/sc85Ax9h7GWIEx1mGMfZQx9g1TtO0APc/q5z0f/RwAGT3PYmmx9iTGwx8CeBNj7DGAX+Ocf3LAcWkAOoC3ASgA2AXw/QD+X8bYZ3HOdc/x/yeAfwrgfwPw3wH4GcbYiwBeAvBW9AbQOwH8CwB/0fPdlwD8BwB+CEAHwA8C+E3G2Odzzl/xa1zfA/gAgEcA/hcALwN4HYC/1W/794/qiCXGLoBTAN8HoAzgBQBvB/AbAL7Yc2wcwC8A+DEAnwbwBgD/kDFW55y/GxAP9ocB5AH8dfTu538F4JcZY1/POf/1Cdr2Of1//8z5Juf8CWOshd79WF5wztd/I/4AvAbAvwfA+39FAP8SwF8Z8b0ggIP+d77B8f47+u99u+O9FAATQAlA3PH+9/SPPXK89xSAAeDA8V4MwDWAn3O8924ATx2v39g/11/ytPOH+ufbHLM/pP553jHGsR8C8MFb9v9L/et9+QTfkQD8x/3vvdbTJxzAGzzH/xaAYwCs//qn0TMMGZ/jPuq9lyPa8i39a36Wz2c5AD+96DE+7G+93BgDvOc5vBbAXwbw9wB8FMA3APgAY+yHnccyxv5bxtifMsYa6D30J/2P/oLPqX/TcY0yerPWH3DOa45jPtH/98Dz3T/gnJ86vl8H8K9wc9Z04ivRexD+LWNMoj8A/xo9r+V1Q7671GCMKYyxt/eXaW0AXQD/T/9jb99b6AURnXgvgEMAtDT8SvS8kKqnrz4A4PMZY/G5/JAlxHq5MSY45xaA3+//gTG2C+D9AP4OY+wfc87L/XXtPwTw4wD+JnpubwC9KH/I57Rlz2tjwHvw+f6Vz/mu8GyQ+2ETwBF6D5AfMkO+u+z4+wC+G8D/DODfAqgD2AfwK7jZd2XOubcPqD/30JvdNwF8e//PDxkAtQGfeUH31C8+kkLPA1xarI3ElOCcnzPGfgq9mMGL6MUt3gDgtznnYm3PGHs4pyZsDXjvbMh3SgCeAPjmAZ8/vWWbFok3APjnnHPamkZ/98APKcaY7DEU1J/UfyX0PJEfG3CO8wna9uf9fz8HwP/naN8DAGEAH5vgXHeOtZEYA4yxHc75hc9Hn9X/l3Y+wrg5u3znnJr1OsbYAS05GGMx9Pgb/2rId94P4L8E0OCcf2LIcauIMG56SIP6PoheP7zX8d4b0FsakpF4P3pLtz/nnLdv0zDO+Qlj7E8BfCuAn3J89G39Nv+m7xeXBGsjMR7+jDH2b9Bboz5BLzr+VehxBX6Rc05xh/cD+EHG2NvR8yy+FMA3zalNVwD+dZ/1SLsbEfR2LQbhPeg9OL/NGPvfAfwpAAXAqwB8LYCv55y3Bn2ZMfZFAB7g2db5I8YY/b7foO8yxo4A/If99zMAbMdxf8Q5P+4f9xKA3wXwnby/qzAC/wljLOl5z+Sc/yp6ff8mxtjL6O1YfCOALxlwnjqA/5UxlkWPIPdXAXw5gO/g/WgigL+N3j38fcbYP0LPy0oB+FwAL3DO/9oY7XXi7QDexxj7J+gFvV+LHpnqnXyJORIA1rsb4/yhZwx+Hb2gnw6gCeBPAPwAAMVxnAbgJ9GLitcBvA/AQ3h2AvBsd0PyXOcpgJ/3vPcSPJF9Og7Afw3gM+gZiT8B8KWe774bjt2N/nuh/vU/0f/eNXoswHd42+PTD+/Gsx0e798Dx3HfMeS473Ac99X9975yxHVfGnK+Rv+YLHqeQbn/9x70DJX3mu9GL+bwJf3frffv6/f4XHcfvZn/DL3Y0AV6uxvf5r2XY46jb0TPMHfQ81r+NoDgosf3qD/a7lljhcB6+Rgf4px/26Lbchswxn4EPQ/m8/h6IC4t1lugaywSfxnAj6wNxHJjHZNYY2HgnL9+0W1YYzTWy4011lhjKNbLjTXWWGMo1kZijTXWGIqlNxKMsa9kjL3ST4l+66Lb4wVj7KCfzv0xxtifM8a+t/9+mjH2W4yxT/X/9U1ZXgQYY0HWU0h6X//1Q8bYh/t9/AuMMWXRbSQwxpKMsV/q52R8nDH2xcvat4yxv94fA3/GGPuXjLHQMvftuFhqI8F60l7/GL18+0cA/ipjbNnSak0A3885f4RegtR/32/jW9GjaL8I4Lf7r5cF3wvg447XPwbgJzjnr0aPY/Bm328tBu8E8H7O+WcB+Hz02r10fct6miHfA+CLOOefix6r8w1Y7r4dD4smaowgn3wxgA84Xr8NwNsW3a4Rbf41AP8ZgFcA7PTf2wHwyqLb1m/LPnoP1peiR/Zi6KW+S359vuC2JtBjuDLP+0vXt+glhp2ip8sh9fv2K5a1byf5W2pPAs86npDD8CzHhaKfsPNa9MRKtvizfI9L+CdkLQL/AD2mKKlHZQBUOOdm//Uy9fFD9Nir/6y/PPopxlgES9i3nPMz9MSDTtBjZlYBfATL27djY9mNxMqgn3H4ywC+j7v1IMB708jC95oZY18DIM85/8ii2zImJABfCOAnOeevRY8O71paLFHfpgB8HXqGbRe9PJqlVVKfBMtuJM7gFlvZx/BU6IWAMSajZyDewzn/lf7bV4yxnf7nO+gJyiwarwfwtX1a93vRW3K8E0CyL6gCLFcf5wDkOOcf7r/+JfSMxjL27ZcDeMI5L/BeCvqvoNffy9q3Y2PZjcQfAXixHyFW0AsETaItOHcwxhh6Umcf55z/uOOjXwfwpv7/34RerGKh4Jy/jXO+zzl/gF5f/g7n/FvRy8SkLM2laCsA8F525CljjJSlvgw97YWl61v0lhmvYz2hYYZnbV3Kvp0Iiw6KjBEQ+ioAn0Qv2/GHFt0en/aRjuK/R0/W7qP9NmfQCxB+CsC/AZBedFs97X4JwPv6/38BvbToT6Mnzqsuun2Odn4BgH/X799fRS9deyn7FsD/hF527Z+hp4StLnPfjvu3pmWvscYaQ7Hsy4011lhjwVgbiTXWWGMo1kZijTXWGIq1kVhjjTWGYmWMBGPsLaOPWg6sUluB1WrvKrUVWL32+mEhRmLKzM5V6uxVaiuwWu1dpbYCq9feG7hzI7EimZ1rrLFGH3fOk2CMfTF68vJf0X/9NgDgnP/9Qd9JJpNc0zSkUv6yAcFgEKqqDr2uYRgwTXPoMYMgSRIURYFt2+h0OhjVZ+VyeWBblxHL2l5ZliHLMkzThGH0qh2O21b6jvdeMcagqiqCweBc2uyFX3tpHFmWhU6nA9u2xWeKokCSbkrPBgIBqKqKQGA+8/r5+TkqlQrz+2wRQrh+mZ1/0XtQfy33FgDY3t7G+973voEnTKfTODo6GtqBuVwOV1d+5TNHI5PJ4PDwEK1WC6enpzAMA5ZljTQWa0wPxhj29vawtbWFQqGA09PTsfrbtm3Yto1yuYxcLud6AIHehPLgwQMkk94aP3eHZrOJJ0+eoF6v4+TkBI1GA7Ztg3OO7e1tbG1tgTHmMmSapuHhw4fQNG0ubXrjG9848LOlVcvmnL8LwLsA4NGjR0vxNGqahoODA3Q6HVxcXKDT6Sy6SWt4UKlUUCqV0O12l96Iy7KM3d1ddLtdXF1doV6vo1wuo9VqIR6PY3NzE700kMViEUZiJTI7/RAMBhGNRiHL8p25q34DfRkGzl3BkRcxFjqdDmq1Ghhj4s+JQCCwNP3HGEM4HIZt27i+7hUW73Q66HQ6kGV5wa17hkUYCZHZiZ5xeAOAb1lAO5Yetm2jVCqh1XpWnjMejy9l/GAeKJfL6HQ6aLcnr9eraRqy2ewNg8AYm5vLfl9x50aCc24yxv4HAB9ATwfwZzjnfz7ia88lbNtGtVpFtVoV7wWDwefCSHDO0Ww20Ww2p/q+pmnIZDJzC/Q9T1hITIJz/hvoVeieCXRdx9XVFVRVRTKZnPnAaLfbrvNLkoRsNotu11vpvheUqtfrc1sPN5tNXFxcQNM0JBKJpXGdlwXRaBQ7OzvQNG3p+qbdbqNWq4mdDQJjDMlkEoryTEg7Eoksoom+WNrA5SRotVpot9uIRCKIxWIzNxJ0/mg0ilgsBlmWsbGx4XtsPp9HvV6f6fWdaDQaaDQaSKVSiMVidxYbWRXEYjHEYrFFN8MXFPB2GgigZyRSqdTSeogrYSRM00SlUkEkEhkY0OGco9vtolKpQFEURKPRiR4gzjkajQZM00QkEnFZdfp8jfFgWRYajcaNh8EJVVURDofFsd6tSidCoRDC4fA8mrp0aLfbaLfbUFV1am/CNE00m82h/U9QFGXkdVbCSBiGgVwuh6Ojo6FRXzpOVVU8ePBgooFlmiaurq7QbDZxcHCAdDo9i6Y/lzAMA+fn59B1feAxqVQKh4eH6HQ6ODs7E2QpP2xsbCzl8mEeKJfLuLq6QiaTQTgcnuo3U5+Os0Ufj8dxdHQ09JiVMBKcc1iWhXa77eo0RVFcMz5tl1mWhVar5Zqd/OIHXhARZ5DXYFkWms0mFEVBKBTyXdbIsoxoNArTNKHr+lQeCDHyiLQF9G58t9sVv5lmC1mWEQqFJhpMtm1D13XRP4wxKIoy0203zvlQ74D6hY4bdqxhGEMDmMSi9GMqrhokSYKmaWJcE5t40HgbhFF9ShhnfK5Mr1qWhYuLC1dHbW5uYmvrZsmFbreL8/Nz14Mzjus1Crqu4/T0FKqq4vDwEKFQ6MYxiUQC0WgUtVoNp6enU1232+3i7OwM7XYbpmmCc45SqYRSqYRsNovt7W00m00cHx8jHA7j4ODgxvJonPPTTM8Yw+7u7tJ6T7VabaiRCAQC2N3dXdo1/STIZDIi+E7btQcHB5BleWFGcGWMBOf8Ru7FoAeQ4hOTgDEGWZaH8vpt24ZhGGCMjZwlbxPDsG0b3W7X5YJTLgJ5GDT7S5J041qmacK2bQSDQQSDQdi2DdM0xW/0np8xNhMjSggEAuI6g0ADPhAICANH7Xb+jmHtYoxBkiRIkiT6hhAMBpfGs7AsC5ZljTUm6Z4RqH9u+1sG9SWRt4beq1td+R4hGAxie3sbnPOJZmUvqtUq8vk8ut3uWO7epKjVatB1HbFYDDs7Ozc+t20b+Xwe1WoVm5ubyGQyqNfruLy8RDgcxu7u7szb5IUsy9jf3x9pJAKBAEKhkCs24YxjXF9fCybioHPs7u4iHA6jUCi4jk0mk9je3l6KOEa1WkWhUJjbmBgF27YF7duLeDwOzvnQmNBKGwnbtmFZFhhjt972nJSJR9f2gtbP03oSFBOh79PakgZXt9tFt9sV2ZF+1+l2u+h0OsLz6na7aLVaYIyJ2dr7PYrlzIK2HAgExu5LOjYQCLjuIQ3cYcsMWZbR7XZFDAp4NhNT7sY0v8VvPA2LVQ0CxVs6nc7EY4LaMM24pu+SF8k5F23wIhgMolarDfXYVtpIVKtVGIaBaDSKjY2NO5s1TNPExcWF77LkNklf7XYb+XwehmHAMAzhFTSbzRvU5GazidPTU7RaLRwdHYlU+UAggGw2i0QicSN9nmIqfsuxUqmERqOBZDK5tLEJLyhO5fT8XnjhBdEf004ciqJga2tLBHJt20axWJyY/1IqlYTnN6mBicViyGazU+UJqaqK/f19dDod5PP5oRIJ7XZbZDYPwkobCV3X0el0wBhDJpO5M2KRZVmo1WqjD5wQpmmiWq2KB9i2bTQaDRctm0CcEFmWb8wCg/a9u93ujXORYXXuzy8TGGMDHzDbtm9Qtznnt2aiBoNBxONx0Re2bU98vznnaLfbqFQqU3mViqIgmUxO9Tuo/YZh4Pr62pXs5m0LjYlhhmSljUQ8Hkc8Hodt27i4uICqqkin088VC7Hb7eLy8hLNZhOZTGaieEogEEA6nXbt0gwyMJZloVQquWacRCIxN3YjYwyJRAKyLKPRaKBSqYz1vbOzM3S7XUQiEaRSKfGQBYNBMTPfBZxU60naP0sEg0FsbGwgFovBNE2Ew2FUq9WJPaKVNhKRSARbW1u4vr4W24GJROK5MxLFYhGdTgexWGxiI5FKpRCPx0ceS0aC1v60UzJPCjRRrBljqFarY83IV1dXgox0eHgolhyqqgqjc1dwUsTHbf8sEQwGkU6nBS+G+DX33kgQfbrdbottrlarJdbZpVLJd7soGo3eqxRhVVXFbxplFDVNw8bGxo1BSluVTrRaLd8Al3cLje6Dc92vKAri8fhYLrKqqojH4zBNE7VaTQzoaDQqzt9sNtFqtRAOh7GxsYFOp4N6vS6CuLQMcHo3kUjE1xuyLMsl6OJnTFVVRSwWQygUmulEQ+0fBM456vW6a2dH13UUCgXRplnlI0UiEWxsbEDX9bGNxcoZCaBHXS0Wi7AsSwwYiuBeXFzcOJ6k0O6TkdA0Dfv7+wgGgyMfykgkMpCi7v1uvV7H+fm576znfc+bxp5IJBCJRMba049EItjb20O73Uaz2YQkSdjc3HQdc3Z2hlarhWg0ikgkgmq1ikajIT63LAuFQsE12Hd2dnyNBNHug8EgZFn2NRKapmFvb2/m/IpYLCaMnx9s28bJyYnLSFCsJR6PIxKJzMxIJJNJJBIJFAoFNBqN+8W4dCIUConZwG8rzwtiLOq6DlmWfR8Y2opzDpBOpyPctEUYGMaYGPDtdts1Y3qVlyiIZ9s2NE274SFMEgAblwzmPcYwDNRqNSiKgnA47DuwiWJMn0uShHg8jk6ng1ar5fJWKB3eMAy0223IsoxEIoF2u41isQhd12/I1FGwkCYPut+SJIlrDvttfv1EClJEtZ9mB2tY//t95qStzwKapt1IU3BKGgzznFbOSDDGkM1mkU6nJ7Kujx8/RqlUQiaTwd7e3o0bI8syDg8PXRa/Uqng8vISqVQK+/v7dy5gEgwGsbm5CcuycH5+jlKpNPBY2g4MBoM4ODhYiNArbaeFQiE8ePDAd6eESE7ExwiFQmK77vj42KXClUqlkEgkUCqVcHZ2hnA4jMPDQ5RKJXzsYx9DtVq9QU6qVCqo1WqCYxCNRnF0dIRIJIIHDx5MRZRzjrnLy8upBZUXhUAggK2tLVdfkcdH7w3b1VoJIxEMBqFpmkh4GkUyoaUHsScDgYCYBVqtlss9JalyoLcOdFpUIiTRTEbS+vPiY9DvDAaDgicRDAZ9f69pmmJ2pTZJkgRZlm9lzCjByDTNicVkiTrvXAZ6Qd6DE7QE0DRNkKic99nryXU6HaiqClmWb8zqxDFxHhsKhRCJRBCNRkWA17IshMPhiUhfNFaGZRc72z8JyPsistwkoNIDBKKAO++BdwyFQiHXhLjynoSiKDg6OkIul3OtSQeBErw6nQ729vZcEfhareYiJtFMFggEbiSQ0d5xo9HA06dPEYlEsL+/P7ecACdF+fT0dGiqdbPZxNOnTxEOh7G/v49IJILd3d2hmhvjIJlMIhwOo16v4+zs7M4i8kSxNk0TZ2dnLl5CPB4XgrH0+smTJygUCjg7O3MFWsvlMgqFgmh3IBDApz/9aYRCITx58gTxeBwPHjxAKpXCF3zBF+DFF1+cqJ2jdoNo7E2ygxAIBLC5uYl0Oo1CoYBCoTBRmxKJhJDhB3rB51wuN5Qg5e3TYR7WShgJsuBkMYfNVARKqqEZkY6n953npjX4oE4lyvK8a204vRpFUcQ1LcsSs60TTro2JXzdlgzl9NqcSVrUB+PGKqjvvYFVSi4j2jDBmbBGaet0n71JT+FwGMlkUuxmkRwceTJe40pEsVgsBl3XEYlEhNhNt9sV3to4oISyYZ9PszNCHhb1FfXPOOeiY+lfy7Igy7LoD7975pdINvA3TfxrFoRgMIidnR10u12RwDQIkiRhb29PsMmIRzAtotEotra2Rg6QWUGWZezt7cEwDFxcXKDVaiGTyfjOYPPKdqQ1PA0wIm2No1xtGIZIqd/e3na555VKRWxDOmc/Aq2faVYtl8s3zh+NRvG6170O9Xodqqri4uIC+Xx+KCuSZniaMSuVCjY3NwXpatgW5bzBOReyhzROY7EYNjc3x6JlVyoVYQS3traEd2wYxtj3bBhWykiQe1SpVFwegBeBQEBIo5VKpVtrTkqS5NqGciYO0fVnGaeg9quqiuvra+i6Dk3TfPUr5gVJklxrVsMwRObmqN0P27bRarVgGAYymYyrv5x1JWzb9k0oU1UViqIMnAhkWcbm5iZisRgymQx0XReaEzSjetvIOUer1RJcC0mSUK/XUa1WEQqFXLsJ4yaGzereexOwKA5DRLJRoDgMBSKpPswk92wYVsJIKIqCvb09FItFtNttpNNpsW/uN9PMGpRMRSAhXEmSXG2aNfswEAhgY2MD8Xgc19fXcxXYHQVJkrC1tQXDMFAsFl27EINACWqVSgWZTMZldKhPQ6EQNjY2xGzJOUexWBREqmGQZRmf93mfhwcPHuDw8BCFQgGf+MQnIEkSGo0GSqXS0AejXC7j5OQEiqLg4OBAlHGkNg3z0BqNBq6vr6GqKrLZ7K3IV7R74hw/qqpObHwoFuFsP92zUqk0dXmClTASkiQhnU6jWq0K1WqylNMm0EwCmv0IqqoilUohGAyK2UjTtJkbCcaYIOK02+2FGolAIIBEIgHbtlGv18c2ErQdSbsLBOrTaDTqSs6j849j/CVJEroV4XAYmUwGrVZLBP6ur68Hjg1idJZKJaHLQQlR4XAY6XR6qJHodDoolUqIRqO3zhdijIkxfRs4+zSdTkNRFHHPGo3G/TYSQG+QZjIZ4UG0Wi3xUDrXzeVyWQQmKTchFAqNlECbBJZloVgsCqJOOByea50Exhji8fjIgViv11Gv15FMJudG/iL5d+fSp9VqoVarTWWsDcMQTEigdy+H7eoMahPlZbz44ovgnKNQKCCbzaJWq+HJkyeuzNrr62tB67csCwcHB64lRrfbRaFQEJmYfpH/cDiM7e1tKIoyUwp3vV733cEzTRPlchm2bSOZTIpcFL/tWMMwkM/noSgKUqkUJEkS3xl0/mFYKSORTqdFjgbRdZ3Wt9FouAQ0aEAnk0nBSJwFTNNEoVCAJEk4Ojq6E+JSIpFAIpEY+LlhGHjy5Ana7TZCodDcjYRTT7JQKEydOk8D2olJjQ1lXFJqdSwWQ6lUwubmJs7OzpDL5YSR4JyjXC6jUqkII+FtOwXHaRIYROGeRx/X63Xf1AJd1/H48WOYpimqohOL1AunkQiHw5BlWdyzcWkETqyMkRgH1BnEb6AkJMMwhDuq67pQmY5GoxOrEAPPCgd71boXCacGArnNXtBvXgZJNydmuVyk8n4ARO2JV7/61aKoUbfbFf8SKpUKPvWpTyEWiwk2KKlKUQIZ3W+CV+mJxsQkoGWAc7x6dyJInYu2eb3KZYMw6PNIJCKeA0qMHIV7ZSRUVXVpOFqWhZOTExiGITyKQqEgMguJGDWpkZAkSZSSW5Zak6TRaVkWcrkczs/PbxwTi8Vu5KfcNyQSCZEURa+DwSAajQaePHkiVMydOyfn5+f40Ic+hKOjI2SzWWEMLMvC1dUVAoHAjVosFHglHglR0SeZNOj8zpnd+9B2Oh3kcjmXuPFtQAleFHC/t0YiFAq5goS0BcQ5v/HQaprmIk91Oh0RaBxFoiFPwS/PYxrjMm9QwhfVnPR6OjSLDqsbMg1IV6Lb7U5da2RWoD6gVHQAYl2eSCQQCASg67qIJQEQauKGYaDRaLiWa/RbdF13PcxU18VJ0pumraFQSOg9+KlDETFtVgK61D+T3PuVMxLOZBtCpVJBLpfz1UvY2tpyEWWctOVRVjmVSvnW9WCMLa2wDRFznjx5gq2tLVf6ta7rODk5QSgUwsHBwczW1DRz1+t1nJ6eDpVCuyuQ1gbtCNG/zWYTDx8+FHEl5y4K1TKJxWI4PDwUBpYCoc4Eu3GL3wwDeaTk/S1CvWocrISRIMq0LMviAXU+pDQz+iUleY/VNA3RaHTkbDdtVSuiIzvPQ+2+KwyaKWhgz3q54UzE8ov2eynYdwFnQhbFCqLRKAKBgFDYpofSsixRz4T+aMubPMZ5GT46/6iZnQL2pIAN9ALonU5nKtYtVQYzTXPkb1sJI0FpxDs7O77BoWg0igcPHqDVagmNw0GIx+NjMxenSZSq1Wq4vLwUr0OhEPb29u4swEkELMoKvUtomuaicjuxqACvpmk4PDwU26q0e+Dc0aAt9W63ixdeeEEk2CmKIup6LBqGYeDs7AwAsL+/L0hnRFTzCvaMAilwNRoN3/iVEythJGzbFpWnYWAAACAASURBVCXvBq39FEVBt9sdOWPPO/+i2+3eCAjd9Rp9UVW4KTlsmeCs60FxLG+WJc2mFBeghMBxYgHktTmTs2YB2l2hNpA0AACRik7ez6CsVNoF8XtmnAl1o7ASRgJ4FgkeJrwyjuu0xvMJWZaxu7uLdruNy8tL3y3iVquFk5MTRKNRbG5ujuX9hEIhbG1tiaXWrCaEer2OYrGIarWKp0+fCjalJEnI5/OwbRvZbHZo2vqw+jDOY0YZwpUxErSnPC6cVv0uZ3KnpJwfnG2ZV5zC2YZF7jTcBca9z6RSRXEmb99TdTNijo6bFUrye7Q0dc7aw2Tp/H6H855RygH9ebk/lIBHZfr8ktKI4n5brIyRmASSJCGTyUCSJKGQfFeIRqPY29tztUWSJFiWhevra1cOCNUNmSUYY0in06LGwjyKCC0LgsGgqDVSLpfHYtQSvZ8o/Pl8HtFoVNCWJzXcJL6sKAoymYwIQBIL1BlDa7fbuL6+vjFz+92zRqMhKsuP2l6t1+vI5XIi52TWk8/cjARj7ADAPwewBYADeBfn/J2MsTSAXwDwAMBTAN/MOZ9pKifJs6uqilardadGYhBdlwal07ITS3KWoDyPeDyObrd7r41EIBAQDyIxaUeBHl5KCgN6eRibm5tTPVyGYQjp+0Qi4VqixGIxl0dSqVR8E9f87pmu68jn82PxL2iME/V6ZYwEABPA93PO/5gxFgPwEcbYbwH4DgC/zTn/UcbYWwG8FcAPzvLCNGv7aSDeNah0n1d78S5Aa2uqsSDLslAZX2XWJRGjnGSxQbUp6KFz5vNQMtirXvUqABhYJNlZq4MwqK4Hgc6vqupUQdxmsykEaPxiBbR1axgGstnsxOefBnMbKZzzCwAX/f/XGWMfB7AH4OsAvNQ/7GcBfBAzNhKmad5IGloUSB2IhHnvEkRRpmLAoVAIu7u7d1rFah5QFAXb29uurex0Ou1b6Lher4scDuBZQWW6FxsbG0Ir03t/qK6HE4PqehDo/NOiWq0il8sNDNDT1mcwGMTR0dHU15kEdzKdMMYeAHgtgA8D2OobEAC4RG854vedtwB4CwBsb28734emaVAUBe1229dTIP2CQCAg9r8XiduoAo2CMxOw1Wrd2N3xC9DdB4z6HZQp3G63fWdkqqWRTqdhmiaazaa4R87YxCzvG3lA3W5X1EjxIplM4ujoSChnDbo+kdfuAnM3EoyxKIBfBvB9nPOaJxrNGWO+vcA5fxeAdwHAo0ePxDFUQTyTyeDq6gqXl5c3OlKWZezs7EBVVZyeni4t3XUWUBQF+/v7YIzh6dOn6y3gPhqNBnK53FCuQzqdRiqVEsV7vEzdWSMSiUDTNLRaLRwfH/tOcC+88AKOjo7wyiuviLIKfqCU+LvAXI0EY0xGz0C8h3P+K/23rxhjO5zzC8bYDoCJ1wVEtaYaCHRzLcsS6346ZhYzJyk4E0iTcBLuPiUdOdfNs3D7iaY+bOtVkiSEQqGpovfLCMuyRkb9iRg17B7RvfDWoBiGYffMmdxGdHxn7IfuFdUYcRoiwzCEujiR0uLxuCt50Ym7vI/z3N1gAH4awMc55z/u+OjXAbwJwI/2//21aa/h3WIijcJZIxqNYnd3VwwqUoOeRIWYknmc69m7Ch5SivgicijmgW63i1wuN/QY0l0YB1SDYhwMumeGYSCXy7kk8be3t33jJKqqCjUsauv5+bnL443FYnjw4IFImpsmy3RWmOcofT2ANwJ4mTH20f57b0fPOPwiY+zNAI4BfPO0F/Amb41Dy572OjQLW5YlZgnnjfPW8yDQsbZtQ1XVW9fF8IKIN8NqXI5bv8EPTsMyTcryoLoPtzFYtm3PdNfqNv1D8NZtYYzBMAzfuh5EiSaQari3TaFQCIZhQFEUsfRw9iXFNuj886oLM8/djQ8BGPTEftm8rjtP6LoupMWy2axwPSmV2G8PXFVV7O/vA8BcJPFJlIQxNrE25DhQVVUIxV5cXEzkPVmWhcvLS1+eCqlA3YflzyAUi0XUarVb1fXQNA1HR0di7JFxtG0br7zyCprNJtLpNDKZDGzbxsOHD2f5EwCsKONyUC7/vHYQKNnGNE20Wi0EAoEbOpKDgqO00zIvWJY1M+1OP1CCFP1/XFBiUbPZ9CV0Ucr2LGbxZQTFrTqdjqjoPYqy7wQljlFxHj+BpGq1ikKhAMuyoKrq2EpTk2LljATnHNfX174PBiV4zZoHQFJlkiRhe3v7RiDzPqPT6YhU4nFdfBKSpSi+X/7A5eUlTk9PkUwm8ejRo5kvw5YJ9XodJycniEQiyGazYxmKaDSKg4MDtNvtiWuDzhoraSRI1NQP83BfKSU3Go1ie3t75clIk4Ck3Cf9TrVaRb1ex/X19VBq+Pb2Nl588cV7bSSoFqlt22PX6KD4Vb1eH5r5fBdYOSMxDFRnIBgMolqtwrKsgev0TqeD6+trSJIkNBAHIRwOC6rtfXSNZw2qcBaLxdDpdFy1Uqg2iKZpSCaTqNfrePnllxGNRvGqV71qKQReJoFhGCiXy6LUwKwnEEVRRH3Pk5OTmZ57XNw7I7G1tQXOOR4/fjx0rU4JNIqiIBqNDjUSmqYJqfU1RkOSJGxsbAghF6pS3mq10Gg0cHFxgXQ6jUQigWaziZdffhnxePxGceFVQKfTEcWFYrHYzI2EqqpCr2JRHuxKGAlyeaPR6FgdRSXpSJ5r0UleywbLskQC0TwGthd+S0Aqk0eFcVcVVIJyGnFk0khxamoOuw4VHwKeFUC2bRsbGxuilug8ltsrYSSIqPLgwYOxBjQFGC3LGkh/fZ5hGAYuLi5gmiaOjo4WMkNRQWBStV5VaJom9EMmfUCddTdG7UrQmKYqbiQyQ17u3t7eXLQkgBUxEpQgNcn2Dm03DaMq0zLjNnEG0t4kTQAKci6jIhTRmZ3VoMaFUytS13VX0pyiKFBVVZzfSU0Oh8OwbVtQjJvNpmu3Q9M0QVKj5UgoFFqpVPZJH0zbtkXiIelpjgOnqjbVmHH+WZaFRqMhjqGt+mHjexyK++rciRkjHA6LVNtpB6Rt28jn86jVatja2sLW1haKxaJvLcdlQLvdxsnJiZCUn8Q4Eq08FArdqBERi8Wwu7uLRqPhqrvhrCpGZfBCodCN7WNJkmCaJs7OztBoNLC/vz+07umqo9Pp4OzsDJ1OZ6YJeVQ3hCDLMo6OjobGeSiVYZi3fS+MBNUdkCTJlXg1iCoNYGaS80QvliQJsixDVVWEQiFYlnWjBgih2+0KPsewNjhrdnjreUwC+m6n0xEGggJho4KxROhRVVV8x0svV1V14G8hEpAsy6I+SiwWE/3jPL9t2wP7bFrQOQH4VmO7S5DCNXmbk0gYUA0R+j2WZUGWZZfXRSRDJwlr0O/1jolhfX4vjATxF7rdrlhrAzf59LMGVQhzUrTj8bioHHV+fn7DSBGFu1qtioDTsPNvb28jEong6urKV+F5HFCtCTKaiqJgb29PZIYOg7NuiKIoCAQC2NzcFEV5AUwkJ59MJhGLxVCtVnFxcXHj/LOGrus4OztDIBDA7u7uQuMfzWYTT58+FezdSUA1QEzTxPn5ORqNBjKZDJLJ5A2PUFVV0aeD7i/Vhxk2kRJWxkj4daqzclQ4HEar1YKu60MNA1GsnbhNTMI7sMl6+82qVEeh0+mMJYZDiUCapt2Yqel3DJsB6PNOp4NGoyF+N6WOj/PAkDcjy7KgWpNXMAmoNgX9hm63K7wvMlazrF9B/UP1PRlj6HQ6wvNzXmPS2pjTgtb/04CClE4PdJAXSqnow+4R1fG4NwWDqaLS3t6eSzg2mUwinU6LGW4c1Go1FItFlwrRLFmUdH5vQMo0TVxdXQn23SSg+qfOrcJms4mrq6uhN7lcLqNcLqNQKCCXy4n2xONxHB0djWUkKIHMqQK9ubk5tv6Cs/3OexePx0VgmQY8SdLNYrZvNBooFAqo1WpCjOfs7AyKomBzc9OVT5NMJu9ML/K2CAaD2NracnlyfsfMMvC7EkbCsizUarUb3gQpFI8LmlWr1arYLQmHw8hmszObwZzn917bG9mfBKFQyJVFStHtQbs+nHPoui4k2iuVijjOmVY86jdTLQpCMBhEKpVyXWecfvOqiNu2jWq1KrwdqosxLplqVL0NEsCtVquoVCpCrZxiJE4vTlXVsX/HosEYm3nC4Mjt15lebYlRqVRQr9fFLE41ECjoFolEkMlkViaHgPbndV1HqVRyxWEoAW4Q45TEedvtNtLp9NQzNxmgaDTqMhzjIBwOY39/H7quo1gsTvRdZ42LYrHoG5nXNA37+/tQVRXHx8fCKNi2LVK4neejdP7nDTR+hi3Rnxsj0Wg0XAraznoJ0WgUsVgMsVhsZYwE7TC0Wq0bFZ5qtdrQICeVHOh2u0K1ahrU63Xk83lwzpFMJqdqf6PRmDiBjIovBQIB1Ov1gUZC0zSRjk7gnKNarbqO3dry1WJ+LtDpdFAoFIYGUlfCSGiahkePHk20Dh4ESjIaJ2gTjUZFnYVRrmi9XhdkID8EAgEhukqYh84EPQTE5COPwrncCIVCiEQiaLVaCIfD0HV9bGNB56dcDKDnleXzeZfG47hQFEXEAyZdR9PSx9nuZrPpugd0fho7tm2jVqu5DEur1cLl5SU0TUMikbjzZQcR8fxEiQzDEMuyeUBVVWxubg6Nya2EkYhGo/jCL/zCmdw8KrU+TqcTSWgcVKtV4an4PSjBYHBqdaJJQMuNXC6H8/NzXF5e3miTpmlQVVXkbTQaDRwcHIxlJGzbvuGlOJc20xgJUr6aFH41Li4uLlzy+HR+cqdJLNlpJGhM0PbsXWf6BgKBgXVDqOTfvIxEKBTCzs7O6hsJClxGIhHXbKPrOiqVitgCHRfOgUyBOb+960mM0ixrawSDQUQiEbH1OCkoDbvZbAoadrvdFrUodF1HuVxGt9sVBWc3NzfHPr9fUPYuQeOB+sZZi8ULqnVBlHBSiPLiLn8D1UohY+TVvHRClmVX+2cliKuqKpLJpNDJHNremVxxzqAt0KOjI9c2IAXOUqkUDg4Opjq3YRg4OztDJBLBq1/96lk1+VYgCnQ4HJ54/57ITiTdHgqFUCqVkMvloOu6UNgiFxfozVY7OzuuQsfLDLpnhEAggP39fd+ZWNM0HBwcQNd1HB8f33mpRT+Q7ikZhmE5Rs72P336dGqehRexWAyRSAS1Wm2kTsVKGIlBxCFywWh97LcmJn48FVVttVoud5Torn5Kw3TeWcvVUY0Fgt/5DcNAMBiEoigTu79EGPLWHiEyF6l7ARAU32VMSBsEInU5Xw8jqBFNWdM0WJaFcDh8I0ENgEgyc87w3lopswCpfTv7fJigkTOxa1ag1HbywoeNsZUwEqNAdFfOuevhs20bV1dXor5iPp9HPp9HLpdzkakODw99z0vbpslkEnt7ezNjAubzeVeCVCqVwu7urjg/zZSSJGF/f3/megvdbhdnZ2dCiXnVQVT3Uqk00OBJkoS9vT2RL+LsfzKkNI7oPsiyjP39/ZkHmMkzdtbo2NvbW0hSG42BYZPgShgJmgkGWdNB/HMyGpRQQ2vzer0uLClRgSmRygkS1nXWjqC08Gmqg5mm6Rs4o/YRU45yTohW7Fe7gX6bX3IO/Z5Bs4Mz9d6ZDEdtWDWJPs75DQ+C7qtz4qAxFIlExJhxjhvqb+d55+Fhea8TCARGJnxNklJOIDYrY2xgNTNKaxjmqayEkVAUBYeHhzOpW1Gr1fDkyROEw2GR+ry/v49sNjsyuq/rOs7Pz0Wy0CScCtM0cXFxIZZFTjQaDTx9+lS0iYKzJEpSKpWwubnp4iI0m01cXl6KjFICxSRSqRTq9bpr7U6gZCHa4qVK1YqiIJ1O38kuzLwRi8WwtbUl7pkzfZ0S1PL5/MQcjXmAcz4ygc+ZzTouJEnC7u4uFEXB1dXVUEHioeeZ6lt3DIr2TwOnxxAIBERiSzAYFHTgcDiMSCQycgalNSulbo8LigUQj8I7Q1H6MB1HbeWco91uC5FVJ0zTRKPR8G0HEZVoPe2MT9AM6/3Nuq6j0WjMhIuyDJAkSfBbgsGgiGlxzqFpGjjnI+MNd6Vp6qzRMUtQTMVZdzQQCIAx5pvoOAgrYSSmRSAQwMbGBuLxuCibRkKssyomPAqGYSCfz4tBQOtnv20n2qMPh8PY3Ny8dbCUytjTw5JIJIRReV7qhpCn6LwPAIThHeY9krLTqoIqqAWDQTSbTTDGkEwmkUgkhFT/vckCnRaMMUSjUUSjUcEToHLzs15rOrexvDyMarUqlhgkYOrnWhJvodvtDs3y87u297pALz+Cyr9RzchqtTqUgkuz7SokO40DEpAl4V0nwuHwyqlzTwLikxBITjCdTrtIcesELzzLZzg/P0e328Xu7q7omHg8PpIO3Gq1RCxiY2NDbB05kUgkIEkSGo0GarWaOL8sy9jc3BT1GYbtc5M8u67rNxiQ1WoV3W4X0WjUlXJNtUaAXmq4MyBG6smKoggJuZOTE18jQcaDCiKHw2GXOvMa9wO1Wk3c452dHUGsG4bnwkgAEEpIQK9qFEHTtJFGgjQgYrEYHj586MuCpAQx0rwkUKEaYrYNMxLkEnsj3ZQvUa1WsbW15TISZIRoC89rJIh6TaKrfutsMqJk3CgnYhF5DGvMD877vLGxgYODA9Tr9RsJb17cCyNBmZxUT8IvmBeNRpHJZFCpVJDP50XQJhKJCBd/VLqwYRi4vr6GoigizjEpaAkE9IyPX8XtYWi32ygWi2i1Wi43MRAIIJlMisxKvyAY7V6QrgW5o4ZhIBaLudbf3roYq1KYiJYQ0WjUZeCCwSCSyaSQFlwG5uWq4F4YiUgkgoODA8Go9BoJCtgcHR2J4r9kJIhtlk6n8ZrXvGbodQzDwPn5uRC7nSbFmjGGTCaDdDottkQnQb1e990hoa0927ZxcnLiayRIT7Jer0PXdei6LorRHhwcuIxEu91GLpdDJBIZKYW2TEgkEtjZ2bnhAXlrsayNxPhYOSPBGEMoFHK5/FQPQpZlRKNRGIZxo5aAM7DopHjT/6kWQr1ev3F+gpOANGngk9b5AETdikGuPFXlNgxDzH7eNgy6BtXHoBognU5HeAO2bSORSCAQCCAej7se/Hg8jng8LrgfdJ1ZJRQNgiRJYktyVP2HQXCOiVAoBMYYut2ubx3Y26iOryr8nhnqJ0mSRma+rqSRyGazrmQe2vslinWn08Hx8fFEszSRndrtNvb39ydWWhoFStqyLAu5XG5osKjVauEP//APoWkaXv/610+UeEUalNlsFpeXl7i6ukIsFkM4HBaxEirxRw9RIBDAwcEBNjY27nxZoaoqDg4OwDmf+J4RnGOC2t9oNHB2dubLBZi34Vs2EMHOScajftI0DYeHh6tPywaeqTZTMpRfsJGIM5PoVRKRhYJ7VOS23W4PrCVBtGnKtBz3wSIyEy1XnMxKL72amJmNRgPtdnuiRC+nijgpLJumKWI3QM9zcKZaU3voj/qPZpxZg+4TzXCDUrgBN2V80GD2pvpTPYl56TCsGrziuJZl+Xpafpi7kWCMBQH8OwBnnPOvYYw9BPBeABkAHwHwRs75yAViMBjEzs7O2EWDxwUl20QiERweHiKRSKBYLKJcLmNjY8OXomyaJnK5HGRZxt7e3sTK0Zubm0in06jVajg9PRU1Orwgz8i2bWxvb0/s3aTTacRiMVQqFaG8dHh4KAaHc6eF+jSZTLq0JYihOWtQrRQyfsMeZqoREY1Gsbu7e8NYEkHNyT1ZtczWuwb1KfXRoit4fS+AjwOgfbsfA/ATnPP3Msb+DwBvBvCTo05Cy4lRDDhacw4aIDTonWnTVI+BPAkiEw3iylOq7ziFTfxAYjJUp9GZgONNOKKdiGQyCdM0x0obpkpOdC0nJZfiN1QH1QvyPuYNZ2LRqHtGeQuDYgnk2a0xPsjzopqww4z0XI0EY2wfwFcD+HsA/gbr+ZNfCuBb+of8LIB3YAwjMQ50Xcfl5eXQUu7EdajX6y5Lapqm+C5RueeNZDKJF154AfF4HIFAQCRtkaGgVHe6oc1mc2SNCJpVndL93gLG5AH5DYy7qjDeaDRwfHzsCiYPu2cPHjyAJEkrsxW77KDlJtVvGYZ5exL/AMAPACBBhAyACuecpoQcAN+oHGPsLQDeArjJT8NgmubAPXDa3SCOg23bCAaDrtmp2WwKGi+BHq5x1+WD6Nl+UFVVcDTomjSzAs88CVmWhZK3nyfl3PGgXZphBBnyJOaJUf1G5K5xMK8SgMMwbAfpPsApjTgq1jU3I8EY+xoAec75RxhjL036fc75uwC8CwAePXp068VlMpmEoihCcGUcEFU5EokgnU6PNUCi0ajgbJRKpbECZ5FIRMiZUdVvoPfAk1eQSqV8dSiJu0E3mooALRLdbhfFYhG2bd+qrseiYBgGisWi7/ImkUjcq4rnmqaJdPJBmKcn8XoAX8sY+yoAIfRiEu8EkGSMSX1vYh/AeE/sLUHS+M7aG6NA5CzbtpFKpSaqVFWtVlEul8cyElSdyzCMG5WparWaq6iQF91ud+pCwvOCaZool8swTfNOlm2zhmmauL6+9l3+kDDtfYEsy8hkMkOD03Nb4HHO38Y53+ecPwDwBgC/wzn/VgC/C+Cb+oe9CcCvzeqaiqKIHYlRa2tVVbGxsYFMJjNTJaZWq4Wrq6uxDARF+ClHgtpPZQcty0K5XEY+nxf8gWaziYuLC1cdjWUDDbyNjY2VYWqOC5IamFbAZRWxCJ7EDwJ4L2Ps7wL4EwA/PasTK4qC7e3tsap2U72Bdrs9U6nyZrOJ8/PzsaTPiOVYKpVQr9dF8WIqqkMl2Og1APH/RdWIGAeSJN3bqljk2WUyGZFle99xJ0aCc/5BAB/s//8xgP9o0nPYti2SksLh8NAZKhgMCtqxNzNSVVWkUinoui6UsCmQOQs+gFM/choQe9R7zkKhgMePHyORSEykNTEtSCmcVMHuy64CFdyVZRmtVmtiNShN0xAKhVZKh8IZpwqHwy7ZRdo1GzZJrsydp+3A4+PjgaX0CJTMc3BwcONmxuNxHB4eYmtrS+R77O3tYX9/f2lViDjn+PSnP43f+73fw+PHj+9kmdFqtXBycoLLy8t7letAFOWjo6Op4iWUKJjNZlfGi6AA+MnJyY1dr3a7jdPT04WTqWYC5wxNdGWqCO4HJzedFLO73a5rCzQajd54AObFMBwHJF3nbBstJ4i6Pcu8A+pLv9gJJVvdJwNB8EsAdIKS8YLBoCDNEbyJYyRxd1uDQfVhFEWZC1fFqfHpxDhJfCtjJAhOCu7GxsbQtS/NGplMBpeXlygWi4jH4wiHw6hWqwMFbRdlJEKhkIs2XS6XRyaD3Qbknfl5ZsTEu2+g30yiyH4IhUI4ODiAYRg4OTlxJZ2Vy2UXUY1kCm4zZmzbRj6fF6JCy6ZWvnJGAnhWD2OYBfSrRwE8owOHQiHEYjFxDqrPMMmDQfUenDEPb5ucnsmo2gekaG3btlC7JiKRN0BJtRu8CVlrDIdfjQ4vKJmQEt+cY8SyLJdrrijKTJZ/zvowhmHMzaOl8TpJfZWVNBKj0O12cX5+7nILvWuucDiMo6MjFy37/Px8olRl27ZxeXnpElj1GieKeQQCgYHnJ9oxaWkSAoGASILyBmqp2lQ4HMbu7u5ULmogEBg4c1EC0POMYDCI7e1tl2EvFosoFotzu+b19TVqtRqSySS2t7dnavw55yiXy2J3bNwi0SttJCgxxSso46z9OQi0/ieYpnmj6pVzHef1AKguxqh6CXQdCpI6z0/nJW+A9CVpFlEUBZFIxJdmTt4UtXMaUDVuP1DVML/Zxm8Hhn7PvKpezQPe3+G9z379U6vVXH0yqC+mBXkS89o9ofOHQqGRiV2ElTYSpM8YjUaxsbEBwzBwdXUlOmISBINBbG1tubYXy+UyyuUyGo2Gq/KyLMvY2tqaiChEOy5OV5fOT6C1MCl6t1otqKoqBHwB3Mn2J9DztA4PD2/oEJBiuF+xpHa7jXw+vxKiLowxpNNp1w5Hs9lEsVgc2v5kMunaBZMkaSm5KqNQr9dxfHw81hJ7pY0EqViTMlG320W1Wp0qbZgxdqMwL8mNe42OqqrIZDITGQmnAK6z/U5IkiQov9lsFp1Ox6VXSdWn7gJ+SxySx4tEIr7aFsFgUGhmrgI0TXP9jkAgcKM2h993Jr0HXm9l2HHOz+dZ/2SSimErYySomAjpPi6SzGKaJvL5PFRVvaFBOQqcc1QqFTSbzZGJWJIk4TWveQ22trZQrVbRaDRENS5Ct9vF1dWVoELPiwYtSRLS6TRUVV0pItEygGql0KTjnbnJqwmFQqjX66jX64K5S/dakqSRORbzwkoZCXL9FUVZ6EC1LAulUknEGyY1EtVqdeSMBfRm5ocPH4Jzjlwu55uc1u12USgUhNjtvIwE1eK4L7VC7xLhcBjb29uoVCqoVCo3PqcSjIlEQjCLyUsmkLjx2khMiU6ng2KxCMMw7nRvnx74brcrpOfnAVqqeIsM1+t1l45EpVIZWvyHQFT0VVxLzxOKoiCTycAwDFHp6q4RiUSwsbEhCIPLEAS+F0ai1Wqh3W7feWTdtm0Ui0UwxrC/vz/XeEEqlXKJ4dCShQYyLYHGAeUfrJrOw7yhaRr29vbQbDZ967fcBaigb6lUQrPZXBuJcUGVuQYx5Kh2g2VZaLfbU3kTpP8YDAah67orUGkYBnRdF8sLv0BUu91GrVaDLMu+Dx/VlZhEkckL53VlWUY8HncRfVqtllD7HnaNTqeDWq3mOiYUCt27tO5pQEQqZ0Uzoq9Pq6NJnom36tqwNjjTB4DeGG+32zBNc6zSlLPEShgJivJToVMvotEo9vf30W63cXJyMtXNJOJMJBJBLpdzCbk0m03kcjmEw2EcHBzceJg45yiVSkJh/sGTpwAAIABJREFU289IWJaFi4sLNBqNmSyJSN2b0O128fTpUxHI9Fv7EmjwU1yHMYa9vb07215ddqiqiv39fddS7uzsbGpxn2q1KpaG43oGVCuF0Ol0kMvlYJomDg8Pb+zEzRMjjQRj7LsB/DznfD4JBGOAKNOEbrfrqovhVP6d1D0jkhNt+TnFVslDIS+GBHZt2xZKz4ZhwLIs0RZqg1PnstPpCPXtWSVMUfUlgm3bot2jknaIbEbHBAIBtFothMPhkbVGdF0Xv90L8sao4PEq5354SXW32Yocl7TkhPf+WpYlXt81BX8cT2ILwB8xxv4YwM8A+ABf4EKJErzK5TKy2Sw2NzfRaDTw+PFjAJj4IZRlWdTB9FKbKZrPOcdnPvMZ6LqO4+NjUXVKlmVcXV2hXq9je3vbVVWMQF4QgKmXGbOGYRjI5XJisFE5ARJT8UuaI6q7JEnY3d31TbMmqruu6yPTj9eYDIqiiILWd6VoThhpJDjnP8wY+1sA/gqA7wTwjxhjvwjgpznnn5l3A/1A63qasaapf0H1K0iB2lkD00mhliRJpKSTJxAMBkUtTyq8O8g4DZOKnyWc1cuIBeilGTs9MlqSkedEwd9htS0ondkwjIHHTZI4tGiQBzqslgmNrUV7RVR3ZlbwejfD5v2xYhKcc84YuwRwCcAEkALwS4yx3+Kc/8Dtmjs9aMuPtCInccM0TcP29jYkSXJZZsYYNjY2kEwmUSqVcH19jUgkggcPHghDZFkWisUiut3uVLUr5wGa4SmDkCLkznV0u9121fUgKvok3AdKax6Wvu4tubesKBaLovCRX5IbxZG8nIX7gHq9jkKhMJsKXoyx7wXw7QCKAH4KwN/knHcZYwEAn0KvrsZCQNRSSq92zgajDAZFsP1mPVKvbjabIl04kUi4Kn5dXV0JAzHPNSIlr40KepFQSigUQjweFzVIgGeJV7SkoAeYWHwE8jy8SXNO0C7NKj801B80fijZyft7LcsSleaXGYPuFTC4Cj3tuNBnwzzxcTyJNIBv5Jwfey5u92trLBytVgunp6eio2RZRjabvfWWHjHcwuGw2GIsFosiWcs5W/olPN0WwWAQmUwGmqbh+vp66sHaaDRQLpdvqCwROOe4vr5Gq9UShLRIJIJMJnPvdCps20apVEK73UYqlUIsFkO9XneNH8IkRXUXiXg87uLQEEzTRLFYvPVyd5yYxN8Z8tnHb3X1GcGbrEI5Fbc1EuFwWKR5t1ot1Go1lMtlBINB35syazDGhKJ2u92e2kjouo5isTjUE6FcElmWoaoqLMsauyDRKoFqmVSrVSE8tOqeUSgU8i39aBgGqtXq/I3EGs+gKAqy2ezQIFY0Gp35g0XGIhgMigLCk2wwUe6Aruuueh1U16PdbgtZv/uOQCCAVCoFTdPm4v0tE8gTjUQiqNVqUxvCtZGYAIqiYGdnZyHXpgQg2nKdBFS9jGpG0DKJSGC0M/I8GAnKuHweEAwGkc1mYVmWEP+dBithJKiIb7PZdHENBrmJsiwLFeNIJCI0Le9DrkIoFEI6nXbJ7jlzOJy6Fe12WxDAJq0P2ul0UC6XIcsyotHo3OtuUH0PJ4Go2WyuuRYzwLDA5jhYCSOhKAoODg4E7ZhQq9VwcXFxw/VmjOEzn/kMJEnC4eEhUqkUdnd374WRiMfjLkpuq9XC06dPXUYim80K7QFVVVEsFifeqiWKO23/zjuvQ5Ik7OzsuLyZs7OziWq3rjEfrISRIEUkrzW0bVvUo3CmiQeDQUE8ISLMvEiilFA2j3oJlFhEv4cUnJ394DfD0zGkQUASf96CxKOuTeSrZrMJ0zQRCoWm8igoYUmWZaHyJUmSSwaO6OCTbGOvMT5UVRVjwDAM4SFSQuAwrISRGIVms4mzszMxm6qqisPDw7nPfpZlIZ/Po16vY2dnZ+YJUs4aEdOcP5VKCc+DhHU/+clPTkQPJ4o1UdGniVsQQS2VSiGfzyOfzyMajQoVcTpmUfVO7jtIFT2bzeLy8hKFQkEEquv1OnK53NDv34u7QtRn8hYCgcBcabQ0wxJFmZK85nEdon9P83uIIq1pGqLRqCBbUWUuzrmgnw+iUlMbSB38Nr/FCao1cl9qjC476B5TPRfLskRawqj7cC+MxF3DNE2cnZ2h3W6vRGAtFovh4cOHkGUZx8fHqFQqOD8/h2magpY9T6+Lc45isYhKpTKwaNIad4N0Oo1YLIbr62vk83lomoajo6OheSErZSQCgcCNmgeLAFXPIgMRDAaXev1MSV+RSERULaP4ySi+AMWDblNfwq8+iTOd3XsfB9WtXOP2kGVZVFR3bn3fC0/CWxeDaNJnZ2d33hZZlrGzs+NaYqzCzommaTg4OBB5KJ1OZ2S7VVXF5uamcFNnhWaziZOTE2iahq2tLWH8qQI2ScitsXisjJHwq1sxzoNJs593FrzNTBUIBO5UGWgYJolVyLKMZDIplK/HyUugjNJZL0colmOaJrLZrDASnHM0m825FUm+C4xbZ2ORmKRdK2Mk/BCPx4XM2MnJCQKBALLZrFCaCgQCSKfT2Nvbu2FgdF3HxcUFVFVFOp1euch6u90WSVvjpmWrqoqdnR0kEomBDLy7piobhoHLy0uXqtYqexA05kKhECqViqtiO90z51b9PGul+IGk9Eg4ehys1pPhQTgcxubmJmq1mhDlcGZ/MsYGFkbtdDrI5/MIh8NIJBIrZySo/ZPsqiiKgo2NDbTbbTSbzaVIajIMY6Wqfo1CIBBAMpkU/BSnkfDes3nXSvFDvV7H1dXVRN9ZrSfDg0gkIozE5uamCGwGg0HE43FomjbTdfQi4c3XGFd52Q+SJCGVSol8jmlVoEchEAggHo9DlmU0Go2lMEqzgqqqiMfjN5axs1aQGgftdhuFQgGqqiIWi808iD5XI8EYS6InVPO5ADiAvwbgFQC/AOABgKcAvnlakV0iCum6jv39fZimKUg5W1tbiMViKxFQHAUqDehVwJ7WSMiyLPQwpimuPC6CwSA2NjYQjUZxenp6r4wEKbT7PZDemp7zBpUGJE3WlTISAN4J4P2c829ijCkAwgDeDuC3Oec/yhh7K4C3AvjBaS9AljuZTELXdbTbbRFYnDbgRolRBFojk1KRX7BQ07SJr0X6mnRTScXa7/yzHnS0tekdVJ1OB7quQ5ZlQb6adKuZttUkSRIKSPMyRIsCUd8neSCpVgrJHtq2jWazCdu2oWna1LR+79igcQr0luTBYBCtVkukL0yKuRkJxlgCwF8C8B0AwDk3ABiMsa8D8FL/sJ8F8EHcwkgAvWXH0dERarUajo+PhXIULUEmARF/nNqQJOtGFGUvrZkxht3dXV/hj0GgeIkz9bxer+Pk5OTORFdpW9l5vUKhgIuLC0QiERwcHEwlbKsoCnZ3dyHLMnK53Mxqjaw6SE282Wzi+PgY3W4XFxcXCAaDODg4mJmQEdXoAICjoyOEQiEUCgVUKpWp7sM8PYmHAAoA/hlj7PMBfATA9wLY4pxf9I+5RE+y/wYYY28B8BYA2N7e9r1Au90WilHOKD8tOcYZ3N6qX5R779wxcObjEx3b09Zb0aad17zrLTOvUrSiKKIMoDfhalyQEK6Tvn7fYJom2u22a4tdVVXXa/LGaFlH5CWq8hYMBsW4nYURJU/UOX51XRfkv2nvwzyNhATgCwF8N+f8w4yxd6K3tBDoq3D7PhWc83cBeBcAPHr0yPeYp0+f4uWXXxaZoNOoNHe73RsJLt5z1Ot1XFxczG3AO8+/iPqTTiSTSbFUmJbR6uzTZak1MmvQNiIhFAphf3/fldmazWaRSqVQKBSQz+fFBBAKhXBwcCDqn8xKR7PZbOLp06ci3wbopdszxm41budpJHIAcpzzD/df/xJ6RuKKMbbDOb9gjO0AmFowQNd1VKtVYaGnSQkfVheDUtGpctWsXWZKtJrX+acBJYTdBndVa2SR8Kv14h17RIf3xhrI66AkN0q2mkebZhELmpuR4JxfMsZOGWN/gXP+CoAvA/Cx/t+bAPxo/99fu+21IpEItra20Ol0cH5+ftvTCVQqFZRKJRiGMfNlAO1YUBHhZWXmrTE/kNCObdsuD2TZMO/dje8G8J7+zsZj9CqABQD8ImPszQCOAXzztCen6DKRUshyz2oLiKpveyncflFt5zHjXt+b9PQ8wdmHy+BBzQI0Bry07EETANVKWXbM1Uhwzj8K4It8PvqyWZw/Ho8LcRly4fb29uaSjHR9fS0GsyzL2NjYEFueVLeCVKefF6HV2yAcDiObzQrG5aoHN03TxMXFhVBUd9ZKWXV+yEozLjVNc6k1EZNQVdWZ0qw7nQ5KpZIwEqqqIpVKuXgRrVYLrVZLJE8tc+r4MoByZlqtFkql0qKbc2tYloVKpQJJkhCPx0UFuGKxuOim3RorbSQajQYuLi7Ea0VR5lI0h+pWdDqdG6xHoOc2xmIxRCKRuTDeVh2MMSQSCZdrrWmaWCpSPKlSqSwV6cq2bZTLZRiGgWQyOVZAl77TarUmVihfVtwLI0FrPhJVmTU0TYOmaajX66jVar7HJBIJ30SyNZ4ZCT+ymaIo2NzcFLL/y2QkLMtCqVRCs9mEqqpjGwmqZXJfgtErbSSoBgWBtpUsy0K1WnXtP9ODPg1oABPpyineStJvyxydXgaM8q6cJCTq01artZD1vGVZqNfrMAxjap7HfTEQwIobiWQyicPDQ/GaIuamaeLy8tL1/m3qbpCKEvEwKN4RCASwsbGBRCKxXmLMCKQJkkwmhY7oXcMwDJyfnwtx5ef93q60kVBVFYlEAt1u16WWDUCUkqd6FbepiUHbWFQVLBQKIRqNIhqNimpha0wH27ZF8hHtcHQ6HbRarVvteFDhY8q5GWeb1TRNdDodtNttUa8F6E0yuq67tCHo/M8DVtpIJJNJxGIxVCoV5HI5X9n2ra0tJBKJiZOU/BAKhXB4eIhoNIoXXnhB0JfXmB66riOXy7lyC/L5PIrF4q0o6lTXgyqRjWMkWq0WTk9Pb9DjSXfTuQuTSqWwt7f3XHgZKz3CKTlJURRRS8DLXvSjxY4LqjIVDoeFiA3tYsyjYte8QPRvAiUfLWKAe9vS6XRurP1nwZkIBAKQZVnULRkHtm2j2+36GidqExkQRVGg6/qtxteqYKWNBCEajeLhw4dCPXtWSUXJZFKkTH/2Z3+2q6DMKrmalEBGcJLO7hqVSgWFQkEYcq/RWHZcX1+jVCqhWq3CNE3EYjHs7u7ea4/yXvwySkqyLGvsWcNbX5Q0I5xeyG1jGcsCqvdILjdly1Km5114FJR8RPGGu4z+U0r+qATAQCBw42H3fofSsTVNQ6vVgizL92onww/3wkhMAxLRpViFaZq4urpaeQrtOOh2uzg7OxMchXnnD3DOUSqVJlZpngU0TcP+/r5Q5R6WK6NpGg4PD13aIs/LmBiGlTESzhl/2DHOxKFB+oNAz0twBjS73e69oAf7wdkfVDmrXq8LGvu8t/lIJn8RUvkkitzpdEaqcns9RxoT1G9+Y4/ev89bpSthJEgOrVgsDp0JFEXB9va2a+vKy42IRCJIJpNCu5EGgrNs331DOBzG3t4edF3H9fW1CMzZto1isShEVO+65sayg4R8Y7EYHj9+LCqLAc8q2RcKBRSLRUQiEbzmNa9ZiazOSbESRkKSJGSzWdTr9aEPsizLI3UmaZnhFJ8dZXxWHcQ2rdVqqFQqLiNRqVQEn2RtJNwIBAJIpVIwTROf+MQnkM8/00fSdV0wenO5HJLJJA4ODtZGYlXBGEMkEkE4HJ5LXYJlR7vdFnUv7ot2wyBEIhHxN6v7zBhDPB535ebouv7/t3cuv61sWRn/tqvKLj+qHJedOI6TnBv1oCWEenauEMwaBogJEwYICRAC9Qgh8Rc0g5aYIDEEtcSACboChAQSEwYwQ0JcLi0Qg57ce/OOn7GrbJddVa7NIL32KTtlx45diR/1Gx3nxHalvL32Y631fbAs61XnK6SaHVa70+/3N64xbC+CBPCUziyXQzV3d57BYCCKzXb9JF7XdVQqlbVOBIwxGIYxce9arRZ6vd6r7mcymUSlUnmWguac4/b2Ng4Sr2E8HsM0za3Kp28SdEjrui76/X7owLZtG91uV6hlbyvLemEs+prZbFaUeA+HQ9ESEOxAppToIpW4sw7VM5kMDg4OhDr7JgT1rQgSjuO8qR/FrkFVopZl4fLy8lmwpRRlu91GuVze6iARBYwxlEolFItFPDw84OHhAblcbuL8gTGGZrOJbreL8/Nz6Lr+qvcqFArI5/NotVq4vb2Ng8SiUNpunQRVsHcdUhOfVzgVLLSKeQ418SWTyYngQMrgVIxHhWuyLCOZTIauKHzfF+dDVMFL0Ge1jl6jdbEVQSIKbNvGzc0NXNfdWW+ImPVjGMbEKqHX6+Hm5kasznzfx8PDg3CRC9M7HY1GuL6+RjKZxOnp6cZnRPYmSFDzF0FK1VGdc5DDeZiqdrANedMJruLC/p59Y3qWd11XCDGTaxlVaNI5EEFjglYf5KwVLOCiFR81qE1vN8LGD/nD0Ouvm70IEqRmHdQDiNoti3Qxpz803/dRq9VmyuBtGsPhUAj4HB8fx+cVU1ApN3m+DAYD1Go1oZERzFTkcjkcHx+L7cV4PBZeoESpVIJhGNA0DZ999tmz96PnBF+30+mg2WxC0zSUy+W165vsRZAA3t7jQpZl5HI5SJI0kXr0ff/dOgbp5D84iIIlxWGZARKFoX8vSlCo5y2hs4EoshxhSJKEbDYrZnHOuZA7tCxL+IPSWQM1IZJ/bLBUneoxgE/jZxpqzKO/ld7PNE0kEgl4njex4lvH/d+bIPFeOI6Der0utjWc83fLg5NfZbBNu9FoYDgcir32tFYntZXTvxfBdV3U63X4vi88KN6KbrcLx3GQy+VQLBbffHtEpdz5fB7D4RBXV1fCi4XqVVRVxeHh4UqTBa2OSQbg7u4O9/f3uLq6QjqdxuHhoXifVSUB4iARMZ7nodPpbETZt6IoKBQK4rHneeh2uxiNRshms6GHbLIsL21TQK/reR7y+fybBolgI5lhGBNBgmbwKNOKZK/AOcf19TVarZZopHMcB+12G5lMBoZhrLyi7Pf7InUdbE6k8vpcLid8aFZhp4KE4zh4fHwUZw2MsYX9EtaNbdu4v78Xh0qbSCKRgGEYoox5VUajEdrtNjjnIhhRmfG078ZbQ/0/9EV9y6BN1g/pdDoSX5hZjMdjNJtNmKa50vdg54JEvV4X3g0kRvMeQWI0GqFWq735+y4DBYl1MRqNUK/XoSgKLi4uoCgKvvnmG/R6PVGJ+F5IkoRSqYTxeAzbtt80SFCgLBQKry6yeg0UJCRJgqqqcZCIeX8URYFhGJAkSahe6bo+4Uti2zYGg4HoOn2rMwPf94WXRpQGQJxz8T5RF+pRqTgVcDmOM5HBWxdxkIhZG6QCBXzqTaDOSXpsmibu7u5QKBSQyWTeLEi4rouHh4fIpfPoMJjc6KOCms7ozEGSJGEvuG52OkhQYYskSUilUhMGvzHRMP2ln36sKApyuZxIDS6C67qi1FlV1YWe57qu2ObQKsb3/ciK2CRJEtupXC4Xeg5F/qfzGI1GsCxr4rpnEUxpU/EV3dt1stNBggqXms0mjo+PcXh4+N6XtPeQV8oyAry0+tA0DWdnZwtVFZJ+Ri6Xm3B5i4pkMolqtSoqLMOMpamachacczw+PqLb7cIwjKV9PbLZLM7Pz9deebnTQQKAKGGl1ltFUTZe/pxmBSD6ytC3hma9ZSA/DNrn0/PpPoW9Hq0a6DkvKWXPgzEmzljmQYGPzgpmQZ61YZCq+PRnzjkX92D6tWmlTND9mvf3kpVBcKzNYrO/LWuCWqEpFXR8fLzRPQiKoqBarUJRFNzd3cGyrPe+pI1gMBjg8vJSfHayLKNarc7NmlBBE4BXZzQYYzg6OkI+n5/5O6PRCDc3N/B9/8VVa5h0/0u4roubmxtxQBmE/GGIRfxnTNMULe8nJydz33svggQA0e0ZVuq6iaiqKlzCZFmOdD+9adCsP70lofQloSjKi6us6ecsA+33aaaelUKkmT/YTr5uSPAm7G+RZXki6HDOJ5rDwrZ2tNp4acUBRBwkGGN/DOAPAHAA/wvg9wBUAHwBoAjgvwD8Nuc8upzUFkNepoZhoNFooNvtvvclRQ6dIw0GAxSLxTctPppGkiSUy2VkMpmZAcK2bdRqtchTq8uQSqVweno6VzVe0zR8+PABsiy/eH4RWZBgjFUB/BGAn+Oc24yxvwXwmwB+DcCfc86/YIz9JYDfB/AXa3rPF0tvt8kjgeTMfN/fiwABfMpImaYJTdNC/z/s31GQSCSEe/wsPM+DaZobpUkiSVLovQtCq9RFvgdRbzdkAGnGmAsgA+AewPcB/NbP/v+vAfwJ1hQkSGDUcRw0m83QyE4iIel0GsVi8c27FJfB9320220MBoNIimQ2kUQigVKpBE3Tnn05bdue8A1RVRUnJycvfiFintPr9fD4+AhVVVEsFuf+bmRBgnN+yxj7MwBXAGwA/4Kn7UWHc05KLzcAqmHPZ4z9AMAPgCcdg0VQFAXFYhGj0QidTic0SNi2Ddu2kc/nUSgUNjpIcM7R7XZD02m7SrBdehrHcdBoNESQyGQyGzWDbxO2baPRaEDX9YmmvzCi3G4UAPw6gAsAHQB/B+BXF30+5/zHAH4MAN/73vd4UA7fNM2V/RnJ9o1Uj6PSFKQuUOBJqWgRA2Lf99FqtSBJ0kZ0j24KqVQKR0dHYq9Nh7tRMR6PxUourI0+SmzbRr1eRyqViqTfI5PJoFwuz03HElFuN34FwDec8wYAMMb+AcAvAThgjMk/W02cArh96YVICxD4JNW1apAYDoeiMy/KJjDHcVCr1eD7PlRVXShIkB5DzCSqqqJSqYjHyWRy7dWFQahBilKWbxkkqOVd1/VIMnLLdP5GGSSuAPwCYyyDp+3GLwP4EsC/AfgNPGU4fhfAPy7zonSYVygUZqaEyCQ2mUyi3+/PXJKSXmCv14Prugv5JUxfSzabhSzLczsLSS3JsqxQTc1pBWZ6TswTqVQKBwcHz+7JdOovCuigu9/vh864UXlj0Gu6rotutxtaYPVWRHkm8R+Msb8H8BUAD8B/42n78M8AvmCM/ehnP/urZV6XPBAMw0CtVsNwOAwdPJVKBZ7n4fr6eu6e3nEc3N7eQlEUfPjwYamonUgkcHR0BF3XhXnsLDzPw8PDQ+hpsmEYODs724qMy3tAviHTTEvxRQUZK89ynY+yfsW2bVxfX0f+PvOINAxzzn8I4IdTP/4awOeveb3RaITxeCz8DOYNkFlq1SHXKAphFp0REokEUqmUKHKybXtmlKccdfDMw3GciRXFvhRJvRbySBmPxxiNRsLgmIqc3ipQvAfr8JxhjD3zAPE8D47jLDTmt6biklSCe70eqtXqiyeyUUJl08lkErVaDff39zOl+VVVxdnZ2YQQ7t3d3V5lLFbFNE3c39/DNE3c3NxAURTh4H1+fh67ob8AFeUFy8rb7Tbu7u4Wev5WBAnOuahooyYXOmdQFEUcZr5mb0jNO7MaheY9jzEG13XnZiAoihO+7z9rW9/0hrP3gvbhVFxlWRZM04SiKKKfZZVZdtY+f9FV6KZDY5vcxIJjjh4vctaxFaNzNBrh8vJS2Kk1Gg10Oh1omoaLiwtYloWHh4dXOzyfnJxAVdWl1KBvb2/BGFs6RZlIJHB4eDhRbrxo5du+0W630W63Ua/XhdsadXbe3Nwgm83i9PT01SnCVquFx8fHZz+nIq1FMlGbjCzLYmxPZ2aCB/v39/fzXyfKi1wX5E9AB1We58HzPGiahkwmI/apYbzkM6EoCrLZ7FKptGm/BOB5Ew1lNMJIpVIT7xf2u5tc5PVWDIdDsYLo9XpiEuCcYzgcgjH2qpUE3e/hcBhayborzXSJRAKqqoYexsuyjEwmA8/zXpygtiJIAJ/KdYOpwtFohKurK2GZFvYc8kAgTNNEu90W3gSzTF2XgTH2TOR0MBig0WgsNNj6/T6azab4EiiKgqOjo71W0iIBlsvLy2cZrGQyiaOjI+RyuaVrF3zfR6PRmJDe30csy0Kr1QrVp5hmq4KErusTX8SHhwch4R4GY+xZFKUqumQyiUKhsLZKS/JSICRJQqvVWihIjEYjPD4+TlQSGoax10ECeAqe7Xb72c9lWUY+n4emaaFbApoZw8YF5xy9Xm+lg+Mwf9dtYzgcToy5eWxNkBiPx2i1WhPLw+ASdFGy2SwqlcrCWonvged5aDQaSCaT7+Yb8l7QCsK27ZlOZ7Iso1wuQ9f1Z9tETdOg6zoGgwE6nc7cCUTXdWSzWfT7fZimiVQqJYRlZ60udV2faCijAL8t6mGmaaLX6y0lCLw1QYI6Ilclk8lsvNW753loNpti37hPQcL3fXQ6HTw+Ps4MEoqioFQqhWpNaJqG4+NjtNttdLvduV8EXddxdHSEer0O0zShqirK5fLM1SWtTIMNh5ZliYrIbcA0zaX9YLYmSGwbyWQShmHAcRxYljV3EKVSKRSLRfG7tAT0fR+macLzvJ0PFvS3jkYjNJtNsZoIkkwmkcvlcHBwMDHT05c3lUq9OAHQCkJRFHE/0+m08Cydt7rknGMwGKDZbIoDQfIaoc9uVr3MpkBK3sPhEP1+f7eKqbYN8qDo9/tzKzKBpw8um83CsiwMBoOJINFoNJBIJFCtVnc6SHieh1qtBsuycHV1FZqaTKfTqFar0HV9YrYnD4pFDILpAJyeB2BCu+Kl53e7XZimiWKxiGw2C1VVUa1WMRwOMRqNNj5IHBwcIJ/Po9lsLrzl2OkgQamyYINXcAaJAvKICD7OZDITe2fbtp81nVE6VtM0oexNBWK7kI57CWq0IwPj6WwGtUyT6CvJ06fTaVEsxBiD4zgYjUb42/s6AAAJ1ElEQVRzMxdhgWDR8ylKoY9GI5imKVLVVDa+SVCqnnMu7hPwqcBP0zS4rvtiR/XOB4l6vT4h/VYsFnFychLZoWW328X9/b0Y5Kqq4vT0VGQqfN/Hzc3NzCKes7MzUTy2ajv8NuF5Hu7u7lCv158FRU3TcHJygoODA3z22WdIJpOQJAmSJOH4+Bi5XE6sLB4fH0VrfpTBlXw9iHX0WKwbz/Nwf38PSZJwdnY2UQpAh7a0cpvHzgeJ8Xg8MWuTD4MkSWtNMQb9GIMKxLIsC38D4JMSdBhURkvaE0GiEsV5b0i12bZt9Ho9kb1ijEGSJCiKIma9bDYrtBnp59Pt4uSNGXVachsKrjjn4l5MX2uwHUFV1bnFezsdJMIgVSuandbx5eOco9lsotPpPBugVPAV/BBeklyjBrLgB7vtJcKzIL+KdruNr7/+eqLdvlwuo1gsQtd14VJOgePs7Cy2blwDmUwGHz58mHsfdzZIkEPRdASllQTtX2npuirkYTCN7/tL93dQK/QuQ6u80WiEXq8nDm2DS3jf98WKj/bUiURCuJTv+j2aBZ1VraMJjUq3924lQQ7SYcpVlmUJAVAAIu+9qzP1ptLv90U24+uvv4ZlWRPBlDIWFxcXImuRTqdRLpfFdmMfGY/HqNVqsG0bpVJprqvYutjJIOH7vqgqI2gLQKfSwJOpq+/7KJVKkGX5zSowg94g21jSuw4cxxHpRMuyRH0IfQbk0h2sOFUU5Vn6c98gXxLLsqDr+pt4yOxkkAij0+mIJS3daBJ/oU5QwzAir0VIJBIoFArIZrPodrt7Y7ozDflV2rYNz/NEqbXv+zAMA9lsFt/97ndxdnb2YpHTPiFJEkqlEnRdh+u6uL6+FqnhqNiLIEFCpsFDMcdx0Gq1YNs2dF3HcDiMRLo8DF3XYRgGPM/b2yBBlZV0jiNJkmi4+/DhAwzDQLVanWu8u48wxpDP58E5x/X1NRqNBiRJioPELiBJEvL5PFKp1JtKs28jBwcHKJfLQpYuk8lA07SFVhS5XA5HR0dCi2ITtnPZbHaiG5m8WF5TV0GWj8PhELIs4/j4eCUHM9r2zcu4xUHijaBlYmxJNx9JklAsFlGtfjJ2y+VyqFarC205NE2DpmlotVqwLGsjgsT09VM9yGuDBP1tp6enK6+0yH8mDhJzIMNXKsJZF+SlQaklyu/vO51OB+12W1RFRsWmnWEEr2cZ1THP89Dv98W9ouLAZYIfbbfDsG17d0RnooJ8N9LpNL7zne+sTYU7nU7j/Px84iQ+lqQDrq6u8NVXX72r2cw2Qb4bq1gwUKNgs9l89n+LZNh2MkgkEgnRMhxU1gYg1LaDv5tKpYR/Rr/fnys6siikoThvRgszNN51Zs2EdGaTTqefFUm5rjsxE0qStNGiQdO4rjshlkQNbDT2pj1ZguOC/lZqHKQAsezfvsqqbSeDBKkEe56H29vbCaky8nCgm0Yz/ng8FgVYJycnK68o+v0+vv3227kf5qa3Fb8lqqri48ePKBaLzw52TdOcqHlRVRXn5+dbU5Ld7XYnghxtbWmcBjUwarXahA8sjU8q7w92GL8VWxkkZFmGJEmi9HoaartOJBJiiU/txLRCoOYX+pmiKMIpah17ZZJ+j3mC6iGmBznNlCQLF6bsPL01SSQSQiF9ugiOfneTAvCsrRVdfzDYTReKUVv3eDx+t5XT1gUJxhgODw+h6zra7faEyvS85xiGIQYhmbvc398jmUyKNtp97QWIGt/38dOf/hSXl5fPdEnz+Tw+fvyIXC63cJ0KNYUlk0lUKpWJmbjT6Yj6i03IbOwCWxkkUqkUcrlcqGfCNOTGlE6nkU6nYds2stksXNcVlvJUu7Ate9xtgtzVut3uhLYilaarqopSqbSUVR+Jqbiu+2yGdhxnYVm294K8YJYdb9Q+T/9eZbzSNeztwSUR5rtBpazkI6koCur1Onq9Hg4PD2NfyTUyHo9Rr9fR7/efBfRMJoPDw0MYhrF3NofJZBLlcll0sy76nGq1OhEUVxF01jQNxWIRw+Fw4gwkjJ3+dBhjyGazE198urGKoohS1n6/D8dxIjMhnucDscsEPS6mzyJIvl7TtL1LDZNvyDIHr5IkrbVtgO6/ZVmhqdEgOx0kwqDqt8FggMfHR0iSJIxwUqmU8H0YDofCw2EVyAQokUig3W4vrS2xzYzHYzSbTdTrdZGdoHtKvRmqqr66q9P3fTSbzYn+l03famwaqqqiUqnMLfTbuyCRyWRQLpfR6XTQ6XQgyzJKpZJY9nHORXcmya+vgizLODw8RCKRQK/X26sg4fu+0JwkSL/DMAwcHx+vtIogN7aY15NMJnF4eLhbQYJzLmryZ5WazoM8QEkOnXM+kdUgDwdVVZ+dT1B7s+/7wpVZ07Styde/FZR9GAwGkGUZxWIR/X7/XXL8uwbnHKZpTqTXM5lMpGdpWxkk2u02Hh8fXyXaQh4X9Fq2bePbb78VA3ieh0O328WXX36J8XiMi4sLaJr2oj7gPjIYDPCTn/wEvV4P5+fnODs7w/X1dRwk1gBt4YJbrOPj4zhITLOqohN9+amYhWonqNmF0kuj0Whie9Dv9+F5nmgKG4/HODg4EKm8YLAgfw/SD6RSccaYUNXeVcgVnU7QVVWFaZpwXVeYPm9yyplUsWgrRP4t6/rMPM+DZVliiU/jZ5EGQDoMDgaJVSTsPM970TxqK4PEOkmlUjg9PYXjOLi6upoo/+10Onh4eBCPya7PdV3c3d1BlmVwzlEoFHByciKcoYCnJeDZ2ZmoDgWASqWC8XiM29vbnd5LZ7NZfP755/B9X6Q3JUmCpmmoVCo4OTl5VZ3AW0FjIuiVss7PzHEc3NzciMeSJOH09HQh4RhyOru+vhY/0zTt1TJ2tm3j8vJybgDc+yABPH1IYRqX0+3jQbl8iry0spjlaxA8uSd14039cqyLabVvzrnwx5j2ydhUaEwAmNDeXAfUEhB8vMzKeLrMe5VuWlItn/f+bBvSRYyxBoDL976OmJgd5gPnPFTBZiuCRExMzPuxX6VuMTExSxMHiZiYmLnEQSImJmYucZCIiYmZSxwkYmJi5hIHiZi1wRj7yBj7H8aYyhjLMsb+jzH28+99XTGrEadAY9YKY+xHAFQAaQA3nPM/fedLilmROEjErBXGWBLAfwIYAvhFznlsrrHlxNuNmHVTBJADoOFpRRGz5cQriZi1whj7JwBfALgAUOGc/+E7X1LMimx+p03M1sAY+x0ALuf8bxhjEoB/Z4x9n3P+r+99bTGvJ15JxMTEzCU+k4iJiZlLHCRiYmLmEgeJmJiYucRBIiYmZi5xkIiJiZlLHCRiYmLmEgeJmJiYufw/EbrmaeT1RcMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yz_vKc6GGn1"
      },
      "source": [
        "modelS.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwkAMl7PHQmy",
        "outputId": "42e63556-c40d-415c-b9af-07ec415d39f9"
      },
      "source": [
        "#data_generator = ImageDataGenerator(samplewise_std_normalization=True, preprocessing_function=None)\n",
        "#train_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')\n",
        "#test_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')\n",
        "#validation_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 347 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUZ07ZWKMsg"
      },
      "source": [
        "modelS.fit_generator(\n",
        "    preprocess_function = preprocess_input,\n",
        "    train_generator,\n",
        "    steps_per_epoch=9,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ZjiDxvQ6VV"
      },
      "source": [
        "batch_size = 9\n",
        "epochs = 150"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqqFy18bPpZa"
      },
      "source": [
        "data_gen_with_aug = ImageDataGenerator(\n",
        "    rotation_range=35,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqy0wYhARlfr"
      },
      "source": [
        "sgd=SGD(lr=0.1, decay=0.0, momentum=0.0)\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.1\n",
        "    elif epoch < 100:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "set_lr = LRS(scheduler)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms6FTY-aRKOJ"
      },
      "source": [
        "mcp_save1 = ModelCheckpoint ('/content/drive/MyDrive/DefectDetection/first.hdf5', save_best_only = True, monitor = 'val_acc', mode = 'auto')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTs9Cec0Qv4j",
        "outputId": "8c480c81-b92e-47b0-e181-0cd11deb737d"
      },
      "source": [
        "history = modelS.fit_generator(data_gen_with_aug.flow(X_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(X_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            callbacks=[set_lr, mcp_save1],\n",
        "                            verbose=1)\n",
        "\n",
        "score = modelS.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "23/23 [==============================] - 1s 18ms/step - loss: 0.4135 - accuracy: 0.7971 - val_loss: 0.3969 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8406 - val_loss: 0.4069 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3148 - accuracy: 0.8792 - val_loss: 0.3766 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3502 - accuracy: 0.8261 - val_loss: 1.6213 - val_accuracy: 0.6429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3306 - accuracy: 0.8599 - val_loss: 1.8618 - val_accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2601 - accuracy: 0.8889 - val_loss: 6.0716 - val_accuracy: 0.4143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3642 - accuracy: 0.8599 - val_loss: 0.6123 - val_accuracy: 0.7000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2722 - accuracy: 0.8937 - val_loss: 1.3996 - val_accuracy: 0.5857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.8937 - val_loss: 0.8133 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 0.8599 - val_loss: 0.4219 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2452 - accuracy: 0.9082 - val_loss: 0.4375 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2139 - accuracy: 0.9034 - val_loss: 0.7084 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2138 - accuracy: 0.9324 - val_loss: 0.6767 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3554 - accuracy: 0.8599 - val_loss: 0.7428 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.4055 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2959 - accuracy: 0.8841 - val_loss: 0.5064 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2866 - accuracy: 0.8792 - val_loss: 0.7056 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3649 - accuracy: 0.8599 - val_loss: 0.3538 - val_accuracy: 0.9000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2887 - accuracy: 0.8986 - val_loss: 0.7002 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2474 - accuracy: 0.8986 - val_loss: 0.6192 - val_accuracy: 0.7286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3286 - accuracy: 0.8647 - val_loss: 1.2993 - val_accuracy: 0.6143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3562 - accuracy: 0.8454 - val_loss: 0.6977 - val_accuracy: 0.7000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2783 - accuracy: 0.8841 - val_loss: 1.8748 - val_accuracy: 0.6571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2916 - accuracy: 0.8792 - val_loss: 0.5259 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3747 - accuracy: 0.8502 - val_loss: 0.5208 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3574 - accuracy: 0.8744 - val_loss: 0.6691 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2484 - accuracy: 0.8986 - val_loss: 0.7749 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2927 - accuracy: 0.8599 - val_loss: 0.3839 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3636 - accuracy: 0.8744 - val_loss: 0.3478 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2766 - accuracy: 0.8889 - val_loss: 0.3414 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3130 - accuracy: 0.8696 - val_loss: 0.3516 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3065 - accuracy: 0.8792 - val_loss: 0.3646 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3364 - accuracy: 0.8357 - val_loss: 0.3615 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2336 - accuracy: 0.9179 - val_loss: 0.4015 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 0.8792 - val_loss: 0.5150 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2634 - accuracy: 0.8696 - val_loss: 1.2069 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3037 - accuracy: 0.8502 - val_loss: 0.4240 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2975 - accuracy: 0.8937 - val_loss: 0.4871 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2407 - accuracy: 0.8986 - val_loss: 1.1113 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2533 - accuracy: 0.9082 - val_loss: 0.6736 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2634 - accuracy: 0.8696 - val_loss: 1.6264 - val_accuracy: 0.6571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.8889 - val_loss: 0.8060 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3161 - accuracy: 0.8696 - val_loss: 0.2907 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2696 - accuracy: 0.8889 - val_loss: 0.3053 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2505 - accuracy: 0.8986 - val_loss: 0.5457 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2965 - accuracy: 0.8599 - val_loss: 0.4550 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3996 - accuracy: 0.8357 - val_loss: 0.4599 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2903 - accuracy: 0.8744 - val_loss: 0.3334 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2492 - accuracy: 0.8841 - val_loss: 0.3303 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1631 - accuracy: 0.9517 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.9130 - val_loss: 0.4848 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2326 - accuracy: 0.8937 - val_loss: 0.3914 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2697 - accuracy: 0.9130 - val_loss: 0.3415 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2275 - accuracy: 0.9275 - val_loss: 0.2860 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2742 - accuracy: 0.8937 - val_loss: 0.3179 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2657 - accuracy: 0.8792 - val_loss: 0.3492 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3333 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2841 - accuracy: 0.8841 - val_loss: 0.3231 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2470 - accuracy: 0.8841 - val_loss: 0.3073 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2104 - accuracy: 0.9034 - val_loss: 0.3053 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2080 - accuracy: 0.9034 - val_loss: 0.3044 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1594 - accuracy: 0.9517 - val_loss: 0.3129 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2128 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1682 - accuracy: 0.9324 - val_loss: 0.3168 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2199 - accuracy: 0.9130 - val_loss: 0.3055 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2218 - accuracy: 0.8986 - val_loss: 0.2837 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2144 - accuracy: 0.9227 - val_loss: 0.3030 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2168 - accuracy: 0.9324 - val_loss: 0.3237 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2636 - accuracy: 0.9034 - val_loss: 0.2939 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1890 - accuracy: 0.9179 - val_loss: 0.2996 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1711 - accuracy: 0.9469 - val_loss: 0.2981 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2178 - accuracy: 0.9130 - val_loss: 0.2938 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1935 - accuracy: 0.9275 - val_loss: 0.2932 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1972 - accuracy: 0.9179 - val_loss: 0.2927 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2692 - accuracy: 0.8841 - val_loss: 0.2905 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2388 - accuracy: 0.9082 - val_loss: 0.3008 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1891 - accuracy: 0.9372 - val_loss: 0.3006 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2009 - accuracy: 0.9227 - val_loss: 0.3025 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9275 - val_loss: 0.3029 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1774 - accuracy: 0.9179 - val_loss: 0.2851 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2417 - accuracy: 0.9082 - val_loss: 0.2789 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2032 - accuracy: 0.9324 - val_loss: 0.2695 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2206 - accuracy: 0.9179 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1904 - accuracy: 0.9324 - val_loss: 0.2964 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1837 - accuracy: 0.9082 - val_loss: 0.3083 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2209 - accuracy: 0.9130 - val_loss: 0.3092 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2284 - accuracy: 0.8889 - val_loss: 0.3011 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9227 - val_loss: 0.2806 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2004 - accuracy: 0.8986 - val_loss: 0.2656 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1806 - accuracy: 0.9372 - val_loss: 0.2613 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2130 - accuracy: 0.9082 - val_loss: 0.2892 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2263 - accuracy: 0.8889 - val_loss: 0.3060 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1519 - accuracy: 0.9517 - val_loss: 0.2923 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2548 - accuracy: 0.9082 - val_loss: 0.2842 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1936 - accuracy: 0.9275 - val_loss: 0.2865 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1780 - accuracy: 0.9420 - val_loss: 0.3090 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1500 - accuracy: 0.9517 - val_loss: 0.3028 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2606 - accuracy: 0.8937 - val_loss: 0.2865 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2068 - accuracy: 0.9179 - val_loss: 0.2892 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1499 - accuracy: 0.9372 - val_loss: 0.2976 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1749 - accuracy: 0.9179 - val_loss: 0.2993 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2175 - accuracy: 0.9179 - val_loss: 0.2916 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1729 - accuracy: 0.9469 - val_loss: 0.2903 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2550 - accuracy: 0.8841 - val_loss: 0.2923 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2677 - accuracy: 0.8841 - val_loss: 0.2908 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2062 - accuracy: 0.9227 - val_loss: 0.2951 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1389 - accuracy: 0.9469 - val_loss: 0.2922 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 108/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2523 - accuracy: 0.8841 - val_loss: 0.2918 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 109/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1383 - accuracy: 0.9372 - val_loss: 0.2891 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 110/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.9179 - val_loss: 0.2905 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 111/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2250 - accuracy: 0.9130 - val_loss: 0.2917 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 112/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1621 - accuracy: 0.9227 - val_loss: 0.2897 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 113/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2001 - accuracy: 0.9324 - val_loss: 0.2865 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 114/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2409 - accuracy: 0.9130 - val_loss: 0.2884 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 115/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1194 - accuracy: 0.9372 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 116/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2313 - accuracy: 0.8937 - val_loss: 0.2900 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 117/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1883 - accuracy: 0.9227 - val_loss: 0.2898 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 118/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1668 - accuracy: 0.9420 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 119/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3331 - accuracy: 0.8647 - val_loss: 0.2875 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 120/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1775 - accuracy: 0.9372 - val_loss: 0.2893 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 121/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2562 - accuracy: 0.8937 - val_loss: 0.2914 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 122/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1609 - accuracy: 0.9420 - val_loss: 0.2906 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 123/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2159 - accuracy: 0.8986 - val_loss: 0.2895 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 124/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2153 - accuracy: 0.9227 - val_loss: 0.2912 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 125/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1285 - accuracy: 0.9662 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 126/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2247 - accuracy: 0.9082 - val_loss: 0.2883 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 127/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1560 - accuracy: 0.9469 - val_loss: 0.2906 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 128/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2575 - accuracy: 0.9130 - val_loss: 0.2862 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 129/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9275 - val_loss: 0.2883 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 130/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2447 - accuracy: 0.9275 - val_loss: 0.2934 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 131/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2287 - accuracy: 0.8937 - val_loss: 0.2931 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 132/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1891 - accuracy: 0.9517 - val_loss: 0.2923 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 133/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1613 - accuracy: 0.9227 - val_loss: 0.2951 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 134/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2533 - accuracy: 0.8792 - val_loss: 0.2973 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 135/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2032 - accuracy: 0.9179 - val_loss: 0.2959 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 136/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1655 - accuracy: 0.9275 - val_loss: 0.2935 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 137/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2249 - accuracy: 0.9130 - val_loss: 0.2934 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 138/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2203 - accuracy: 0.9082 - val_loss: 0.2960 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 139/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1456 - accuracy: 0.9517 - val_loss: 0.2929 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 140/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1554 - accuracy: 0.9275 - val_loss: 0.2910 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 141/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2353 - accuracy: 0.8841 - val_loss: 0.2882 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 142/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2314 - accuracy: 0.9082 - val_loss: 0.2879 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 143/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9324 - val_loss: 0.2881 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 144/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1732 - accuracy: 0.9275 - val_loss: 0.2897 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 145/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2011 - accuracy: 0.9227 - val_loss: 0.2905 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 146/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1535 - accuracy: 0.9372 - val_loss: 0.2895 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 147/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2703 - accuracy: 0.8841 - val_loss: 0.2899 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 148/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1484 - accuracy: 0.9324 - val_loss: 0.2874 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 149/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2318 - accuracy: 0.9179 - val_loss: 0.2880 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 150/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2135 - accuracy: 0.9082 - val_loss: 0.2914 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Test loss: 2.7654659748077393\n",
            "Test accuracy: 0.5285714268684387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVGWPuP-oXg2",
        "outputId": "15817b46-031f-4333-dea8-9e2f0aadcfad"
      },
      "source": [
        "model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "history = model.fit_generator(data_gen_with_aug.flow(X_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(X_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            verbose=1)\n",
        "\n",
        "score = modelS.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "23/23 [==============================] - 2s 35ms/step - loss: 0.6940 - accuracy: 0.5261 - val_loss: 0.6757 - val_accuracy: 0.6286\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6097 - accuracy: 0.7007 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5174 - accuracy: 0.7737 - val_loss: 0.6532 - val_accuracy: 0.6571\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6216 - accuracy: 0.7386 - val_loss: 0.6570 - val_accuracy: 0.6571\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5809 - accuracy: 0.7011 - val_loss: 0.6601 - val_accuracy: 0.6286\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5629 - accuracy: 0.7360 - val_loss: 0.6533 - val_accuracy: 0.6429\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5549 - accuracy: 0.7733 - val_loss: 0.6425 - val_accuracy: 0.7000\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4616 - accuracy: 0.7653 - val_loss: 0.6508 - val_accuracy: 0.6429\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4809 - accuracy: 0.7759 - val_loss: 0.6399 - val_accuracy: 0.6714\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5275 - accuracy: 0.7518 - val_loss: 0.5866 - val_accuracy: 0.6286\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5134 - accuracy: 0.7675 - val_loss: 0.5789 - val_accuracy: 0.6571\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4848 - accuracy: 0.7990 - val_loss: 0.6372 - val_accuracy: 0.7286\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.7773 - val_loss: 0.6122 - val_accuracy: 0.7429\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4805 - accuracy: 0.7946 - val_loss: 0.6287 - val_accuracy: 0.6857\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.5036 - accuracy: 0.7567 - val_loss: 0.4771 - val_accuracy: 0.7571\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.8199 - val_loss: 0.5952 - val_accuracy: 0.7000\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5386 - accuracy: 0.7438 - val_loss: 0.4249 - val_accuracy: 0.7857\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4186 - accuracy: 0.8691 - val_loss: 0.4428 - val_accuracy: 0.7857\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4162 - accuracy: 0.8210 - val_loss: 0.4182 - val_accuracy: 0.8143\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4902 - accuracy: 0.7352 - val_loss: 0.5804 - val_accuracy: 0.7571\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.8300 - val_loss: 0.5248 - val_accuracy: 0.7429\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3805 - accuracy: 0.8117 - val_loss: 0.5572 - val_accuracy: 0.6857\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4472 - accuracy: 0.8012 - val_loss: 0.4285 - val_accuracy: 0.8429\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8495 - val_loss: 0.5119 - val_accuracy: 0.7571\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3675 - accuracy: 0.8920 - val_loss: 0.3575 - val_accuracy: 0.8571\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4128 - accuracy: 0.8098 - val_loss: 0.3540 - val_accuracy: 0.8857\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4530 - accuracy: 0.7725 - val_loss: 0.3668 - val_accuracy: 0.8714\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3294 - accuracy: 0.8771 - val_loss: 0.5304 - val_accuracy: 0.7429\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3884 - accuracy: 0.8158 - val_loss: 1.3158 - val_accuracy: 0.3857\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.8169 - val_loss: 0.3823 - val_accuracy: 0.8143\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.3451 - val_accuracy: 0.8571\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4894 - accuracy: 0.8196 - val_loss: 0.5514 - val_accuracy: 0.7857\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3431 - accuracy: 0.8678 - val_loss: 0.3163 - val_accuracy: 0.8571\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4322 - accuracy: 0.8050 - val_loss: 0.3967 - val_accuracy: 0.8143\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8348 - val_loss: 0.3467 - val_accuracy: 0.8000\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.8186 - val_loss: 0.3280 - val_accuracy: 0.8429\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4948 - accuracy: 0.7451 - val_loss: 0.3328 - val_accuracy: 0.8571\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3497 - accuracy: 0.8755 - val_loss: 0.4483 - val_accuracy: 0.8000\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8070 - val_loss: 0.5982 - val_accuracy: 0.7571\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8651 - val_loss: 0.3335 - val_accuracy: 0.8429\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3873 - accuracy: 0.7928 - val_loss: 0.3143 - val_accuracy: 0.8857\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3503 - accuracy: 0.8676 - val_loss: 0.3898 - val_accuracy: 0.7857\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2967 - accuracy: 0.8535 - val_loss: 0.3204 - val_accuracy: 0.8857\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3655 - accuracy: 0.8652 - val_loss: 0.3047 - val_accuracy: 0.8714\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2879 - accuracy: 0.8640 - val_loss: 0.4391 - val_accuracy: 0.8857\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8421 - val_loss: 0.3711 - val_accuracy: 0.8286\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 0.8480 - val_loss: 0.7888 - val_accuracy: 0.7429\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3754 - accuracy: 0.8400 - val_loss: 1.7631 - val_accuracy: 0.6571\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3357 - accuracy: 0.8497 - val_loss: 0.4228 - val_accuracy: 0.8286\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3611 - accuracy: 0.8605 - val_loss: 0.3123 - val_accuracy: 0.8571\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4268 - accuracy: 0.8481 - val_loss: 0.2508 - val_accuracy: 0.8857\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3518 - accuracy: 0.8374 - val_loss: 0.3097 - val_accuracy: 0.8571\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3260 - accuracy: 0.8518 - val_loss: 0.4746 - val_accuracy: 0.7714\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3148 - accuracy: 0.8887 - val_loss: 0.3102 - val_accuracy: 0.8571\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4917 - accuracy: 0.7962 - val_loss: 0.5070 - val_accuracy: 0.7857\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8493 - val_loss: 0.4720 - val_accuracy: 0.7571\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2820 - accuracy: 0.8770 - val_loss: 0.3422 - val_accuracy: 0.8429\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3668 - accuracy: 0.8537 - val_loss: 0.3870 - val_accuracy: 0.8143\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3532 - accuracy: 0.8162 - val_loss: 0.2774 - val_accuracy: 0.8429\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.8850 - val_loss: 2.1476 - val_accuracy: 0.3714\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8316 - val_loss: 0.3314 - val_accuracy: 0.8571\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3560 - accuracy: 0.8430 - val_loss: 0.3760 - val_accuracy: 0.8143\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.8736 - val_loss: 0.8463 - val_accuracy: 0.6571\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3070 - accuracy: 0.8790 - val_loss: 1.7990 - val_accuracy: 0.4429\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3498 - accuracy: 0.8328 - val_loss: 0.4982 - val_accuracy: 0.7429\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 0.8569 - val_loss: 0.4015 - val_accuracy: 0.9000\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3977 - accuracy: 0.8199 - val_loss: 0.3306 - val_accuracy: 0.8714\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.1920 - accuracy: 0.9327 - val_loss: 0.5264 - val_accuracy: 0.8286\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3733 - accuracy: 0.8581 - val_loss: 0.4328 - val_accuracy: 0.8286\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8619 - val_loss: 0.8268 - val_accuracy: 0.7857\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2633 - accuracy: 0.8986 - val_loss: 0.5198 - val_accuracy: 0.7857\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.8273 - val_loss: 0.5856 - val_accuracy: 0.7571\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 0.9136 - val_loss: 0.6584 - val_accuracy: 0.7857\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.8391 - val_loss: 0.3184 - val_accuracy: 0.8571\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2897 - accuracy: 0.9084 - val_loss: 0.3160 - val_accuracy: 0.8429\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3854 - accuracy: 0.8572 - val_loss: 0.4759 - val_accuracy: 0.8143\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2708 - accuracy: 0.8958 - val_loss: 0.7554 - val_accuracy: 0.6714\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3552 - accuracy: 0.8192 - val_loss: 0.3301 - val_accuracy: 0.8429\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3895 - accuracy: 0.8322 - val_loss: 0.3057 - val_accuracy: 0.9000\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2464 - accuracy: 0.9270 - val_loss: 0.2991 - val_accuracy: 0.8857\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4623 - accuracy: 0.8382 - val_loss: 0.3933 - val_accuracy: 0.8000\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3412 - accuracy: 0.8725 - val_loss: 0.3278 - val_accuracy: 0.8714\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3587 - accuracy: 0.8540 - val_loss: 0.3264 - val_accuracy: 0.8714\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2985 - accuracy: 0.8471 - val_loss: 0.3405 - val_accuracy: 0.8143\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.8677 - val_loss: 0.3893 - val_accuracy: 0.8857\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3030 - accuracy: 0.8472 - val_loss: 0.4087 - val_accuracy: 0.8429\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3417 - accuracy: 0.8713 - val_loss: 0.3771 - val_accuracy: 0.8429\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.8923 - val_loss: 0.6401 - val_accuracy: 0.8429\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3162 - accuracy: 0.8897 - val_loss: 0.4167 - val_accuracy: 0.8429\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.2138 - accuracy: 0.9280 - val_loss: 0.3462 - val_accuracy: 0.8571\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2303 - accuracy: 0.9082 - val_loss: 0.4324 - val_accuracy: 0.8286\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2762 - accuracy: 0.8888 - val_loss: 0.6158 - val_accuracy: 0.7571\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3802 - accuracy: 0.8275 - val_loss: 0.4132 - val_accuracy: 0.8429\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2400 - accuracy: 0.8945 - val_loss: 0.3769 - val_accuracy: 0.8286\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.2860 - accuracy: 0.8874 - val_loss: 0.4874 - val_accuracy: 0.8000\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3636 - accuracy: 0.8610 - val_loss: 0.8372 - val_accuracy: 0.6000\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2313 - accuracy: 0.9062 - val_loss: 0.4242 - val_accuracy: 0.8000\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3412 - accuracy: 0.8685 - val_loss: 0.3075 - val_accuracy: 0.9000\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2931 - accuracy: 0.8679 - val_loss: 0.2951 - val_accuracy: 0.9000\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2565 - accuracy: 0.9053 - val_loss: 0.3835 - val_accuracy: 0.8714\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2048 - accuracy: 0.9000 - val_loss: 0.4150 - val_accuracy: 0.8571\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3076 - accuracy: 0.8556 - val_loss: 0.5328 - val_accuracy: 0.8286\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2393 - accuracy: 0.9056 - val_loss: 0.3539 - val_accuracy: 0.8571\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2597 - accuracy: 0.9212 - val_loss: 0.5070 - val_accuracy: 0.8143\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2964 - accuracy: 0.8651 - val_loss: 0.4679 - val_accuracy: 0.8571\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3226 - accuracy: 0.8668 - val_loss: 0.3626 - val_accuracy: 0.8714\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2734 - accuracy: 0.8714 - val_loss: 0.9853 - val_accuracy: 0.6429\n",
            "Epoch 108/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3624 - accuracy: 0.8497 - val_loss: 0.3247 - val_accuracy: 0.8714\n",
            "Epoch 109/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2295 - accuracy: 0.9242 - val_loss: 0.4748 - val_accuracy: 0.8571\n",
            "Epoch 110/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2674 - accuracy: 0.9273 - val_loss: 0.4462 - val_accuracy: 0.8286\n",
            "Epoch 111/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.8506 - val_loss: 0.3046 - val_accuracy: 0.8714\n",
            "Epoch 112/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.8615 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
            "Epoch 113/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2708 - accuracy: 0.8870 - val_loss: 0.3680 - val_accuracy: 0.8429\n",
            "Epoch 114/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3335 - accuracy: 0.8539 - val_loss: 0.3322 - val_accuracy: 0.8286\n",
            "Epoch 115/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.8962 - val_loss: 0.3990 - val_accuracy: 0.8286\n",
            "Epoch 116/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.1803 - accuracy: 0.9305 - val_loss: 0.3262 - val_accuracy: 0.8429\n",
            "Epoch 117/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2959 - accuracy: 0.8950 - val_loss: 0.2721 - val_accuracy: 0.8714\n",
            "Epoch 118/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2211 - accuracy: 0.9183 - val_loss: 0.4409 - val_accuracy: 0.8000\n",
            "Epoch 119/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2345 - accuracy: 0.9056 - val_loss: 0.4440 - val_accuracy: 0.8429\n",
            "Epoch 120/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2015 - accuracy: 0.9115 - val_loss: 0.3680 - val_accuracy: 0.8714\n",
            "Epoch 121/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2375 - accuracy: 0.8908 - val_loss: 0.3390 - val_accuracy: 0.8714\n",
            "Epoch 122/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.2067 - accuracy: 0.9337 - val_loss: 0.4086 - val_accuracy: 0.8000\n",
            "Epoch 123/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2895 - accuracy: 0.8711 - val_loss: 0.3397 - val_accuracy: 0.9000\n",
            "Epoch 124/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2909 - accuracy: 0.8831 - val_loss: 0.3428 - val_accuracy: 0.8571\n",
            "Epoch 125/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3205 - accuracy: 0.8674 - val_loss: 0.4333 - val_accuracy: 0.8429\n",
            "Epoch 126/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2972 - accuracy: 0.8921 - val_loss: 0.3192 - val_accuracy: 0.9000\n",
            "Epoch 127/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.9334 - val_loss: 0.3000 - val_accuracy: 0.9143\n",
            "Epoch 128/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3605 - accuracy: 0.8505 - val_loss: 0.3173 - val_accuracy: 0.8714\n",
            "Epoch 129/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2976 - accuracy: 0.8890 - val_loss: 0.3781 - val_accuracy: 0.8714\n",
            "Epoch 130/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.1751 - accuracy: 0.9300 - val_loss: 0.5253 - val_accuracy: 0.7857\n",
            "Epoch 131/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3288 - accuracy: 0.8540 - val_loss: 0.2615 - val_accuracy: 0.8857\n",
            "Epoch 132/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2355 - accuracy: 0.9207 - val_loss: 0.3745 - val_accuracy: 0.8429\n",
            "Epoch 133/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2792 - accuracy: 0.9162 - val_loss: 1.1196 - val_accuracy: 0.5571\n",
            "Epoch 134/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3011 - accuracy: 0.8697 - val_loss: 0.5042 - val_accuracy: 0.7571\n",
            "Epoch 135/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2550 - accuracy: 0.8885 - val_loss: 0.3640 - val_accuracy: 0.8286\n",
            "Epoch 136/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2192 - accuracy: 0.9150 - val_loss: 0.5459 - val_accuracy: 0.8143\n",
            "Epoch 137/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3693 - accuracy: 0.8803 - val_loss: 0.3866 - val_accuracy: 0.8571\n",
            "Epoch 138/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2758 - accuracy: 0.8773 - val_loss: 0.6599 - val_accuracy: 0.7714\n",
            "Epoch 139/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3103 - accuracy: 0.9053 - val_loss: 0.6665 - val_accuracy: 0.7429\n",
            "Epoch 140/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2614 - accuracy: 0.9090 - val_loss: 0.4791 - val_accuracy: 0.8714\n",
            "Epoch 141/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2107 - accuracy: 0.9007 - val_loss: 0.3903 - val_accuracy: 0.8286\n",
            "Epoch 142/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9072 - val_loss: 0.2905 - val_accuracy: 0.8857\n",
            "Epoch 143/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2563 - accuracy: 0.9356 - val_loss: 0.3125 - val_accuracy: 0.8714\n",
            "Epoch 144/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2029 - accuracy: 0.9237 - val_loss: 0.3797 - val_accuracy: 0.8857\n",
            "Epoch 145/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2488 - accuracy: 0.9077 - val_loss: 0.3311 - val_accuracy: 0.8143\n",
            "Epoch 146/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2346 - accuracy: 0.9137 - val_loss: 0.3991 - val_accuracy: 0.8143\n",
            "Epoch 147/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.1941 - accuracy: 0.9387 - val_loss: 0.7941 - val_accuracy: 0.6857\n",
            "Epoch 148/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4452 - accuracy: 0.8178 - val_loss: 0.3389 - val_accuracy: 0.8286\n",
            "Epoch 149/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2374 - accuracy: 0.9063 - val_loss: 0.4831 - val_accuracy: 0.8000\n",
            "Epoch 150/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.2384 - accuracy: 0.9229 - val_loss: 0.3482 - val_accuracy: 0.8571\n",
            "Test loss: 2.7654659748077393\n",
            "Test accuracy: 0.5285714268684387\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}